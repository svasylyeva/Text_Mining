{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Import libraries\n",
    "import nltk.translate.chrf_score as chrf\n",
    "from rouge import Rouge\n",
    "import nltk\n",
    "import nltk.translate.gleu_score as gleu\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "try:\n",
    "  nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "  nltk.download('punkt')\n",
    "import nltk.translate.meteor_score as meteor\n",
    "import nltk.translate.nist_score as nist\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "#import spacy\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import itertools\n",
    "\n",
    "import codecs\n",
    "import jieba\n",
    "#Import nltk Snowball stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from stop_words import get_stop_words\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import bert_score as bert\n",
    "\n",
    "\n",
    "#Import the Voikko to work with finnish lemmas\n",
    "import libvoikko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cs = pd.read_csv(\"corpus/cs-en/scores.csv\")\n",
    "scores_de = pd.read_csv(\"corpus/de-en/scores.csv\")\n",
    "scores_en_fi = pd.read_csv(\"corpus/en-fi/scores.csv\")\n",
    "scores_en_zh = pd.read_csv(\"corpus/en-zh/scores.csv\")\n",
    "scores_ru = pd.read_csv(\"corpus/ru-en/scores.csv\")\n",
    "scores_zh = pd.read_csv(\"corpus/zh-en/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uchopíte pak zbraň mezi své předloktí a rameno...</td>\n",
       "      <td>You will then grab the weapon between your for...</td>\n",
       "      <td>You then grasp the gun between your forearm an...</td>\n",
       "      <td>-0.675383</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Uchopíte pak zbraň mezi své předloktí a rameno...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  You will then grab the weapon between your for...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  You then grasp the gun between your forearm an... -0.675383       60.0   \n",
       "\n",
       "   annotators  \n",
       "0           3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check all csv files\n",
    "scores_cs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ihr Zeitlupentempo maßen sie, als sie vor Spit...</td>\n",
       "      <td>Her timeless pace measures them when they equi...</td>\n",
       "      <td>Their slow speed was measured by researchers o...</td>\n",
       "      <td>-0.345024</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Ihr Zeitlupentempo maßen sie, als sie vor Spit...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Her timeless pace measures them when they equi...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Their slow speed was measured by researchers o... -0.345024       76.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_de.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananasta, koirasta tai Roy...</td>\n",
       "      <td>Voit muuttaa itsesi ananakseksi, koiraksi tai ...</td>\n",
       "      <td>-0.286195</td>\n",
       "      <td>34.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Voit muuttaa itsesi ananasta, koirasta tai Roy...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Voit muuttaa itsesi ananakseksi, koiraksi tai ... -0.286195       34.2   \n",
       "\n",
       "   annotators  \n",
       "0           5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_en_fi.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"In the GISS model's simulation, Venus' slow s...</td>\n",
       "      <td>GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...</td>\n",
       "      <td>戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模...</td>\n",
       "      <td>-1.171867</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  \"In the GISS model's simulation, Venus' slow s...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  GSIS的科学家AnthonyDelGenio在新闻稿中解释说：“在GISS模型的模拟模型中...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  戈达德太空研究所科学家安东尼·德尔·杰尼奥在新闻发布会上解释说：“在戈达德太空研究所的模型模... -1.171867       50.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_en_zh.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В этом году крымчане получат уведомление на оп...</td>\n",
       "      <td>This year the Crimeans will receive a notice f...</td>\n",
       "      <td>This year, residents of Crimea will receive a ...</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  В этом году крымчане получат уведомление на оп...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  This year the Crimeans will receive a notice f...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  This year, residents of Crimea will receive a ...  0.878043       92.0   \n",
       "\n",
       "   annotators  \n",
       "0           1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ru.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。</td>\n",
       "      <td>His character is good for the British horse, b...</td>\n",
       "      <td>He's a lively character which is good for Brit...</td>\n",
       "      <td>0.625559</td>\n",
       "      <td>92.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   source  \\\n",
       "0  他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。   \n",
       "\n",
       "                                           reference  \\\n",
       "0  His character is good for the British horse, b...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  He's a lively character which is good for Brit...  0.625559      92.75   \n",
       "\n",
       "   annotators  \n",
       "0           4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_zh.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with contractions using pycontractions lib that returns a proper form for\n",
    "# shortened version of the spoken and written forms \n",
    "# without ambiguous \"you'd\" -> \"you had / you would\"\n",
    "\n",
    "from pycontractions import Contractions\n",
    "\n",
    "# Download 'GoogleNews-vectors-negative300.bin' file to a folder with this jupiter notebook\n",
    "# if needed (size is more 3 Gb)\n",
    "# archive on - https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "cont = Contractions('GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "# prevents loading on first expand_texts call\n",
    "# usually takes time\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how pycontractions works:\n",
    "a = scores_de.translation\n",
    "a[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series(list(cont.expand_texts(a, precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it is now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how contracion expanding worked\n",
    "b[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As contraction extractions work really slow\n",
    "# they were done outside preprocessing function\n",
    "references_cs = pd.Series(list(cont.expand_texts(scores_cs['reference'], precise=True)))\n",
    "references_de = pd.Series(list(cont.expand_texts(scores_de['reference'], precise=True)))\n",
    "references_ru = pd.Series(list(cont.expand_texts(scores_ru['reference'], precise=True)))\n",
    "references_zh = pd.Series(list(cont.expand_texts(scores_zh['reference'], precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for translations\n",
    "translation_cs = pd.Series(list(cont.expand_texts(scores_cs['translation'], precise=True)))\n",
    "translation_de = pd.Series(list(cont.expand_texts(scores_de['translation'], precise=True)))\n",
    "translation_ru = pd.Series(list(cont.expand_texts(scores_ru['translation'], precise=True)))\n",
    "translation_zh = pd.Series(list(cont.expand_texts(scores_zh['translation'], precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.    ---->  \n",
      " it is now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.\n"
     ]
    }
   ],
   "source": [
    "# Check how expanding contractions worked\n",
    "print(scores_de['translation'][6], '   ---->  \\n', translation_de[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8072"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# release references and 'garbage collect' to free memory\n",
    "import gc\n",
    "del cont\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(series, lang, pontuation = False, lemmatize=False, stemmer=False, stop_words = False):\n",
    "    processed_corpus = []\n",
    "\n",
    "    for i in tqdm(range(len(series))):\n",
    "        text = series[i]\n",
    "        \n",
    "        #LOWERCASE\n",
    "        text = text.lower()\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        #REMOVE PONTUATION\n",
    "        if pontuation==True:\n",
    "            text = re.sub(r'[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，？、~@#￥%……&*（）:：；《）《》“”()»〔〕-]+', ' ', text)\n",
    "           \n",
    "        #LEMMATIZATION\n",
    "        if lemmatize==True:\n",
    "            if lang == 'eng':\n",
    "                lemma = WordNetLemmatizer()\n",
    "                text = ' '.join([lemma.lemmatize(word) for word in text.split()])\n",
    "            elif lang == 'finnish':\n",
    "                temp = []\n",
    "                v = libvoikko.Voikko(u\"fi\")\n",
    "                for word in text.split():\n",
    "                    voikko_dict = v.analyze(word)\n",
    "                    try:\n",
    "                        t = voikko_dict[0]['BASEFORM']\n",
    "                        temp.append(t)\n",
    "                    except:\n",
    "                        temp.append(word)\n",
    "                        continue\n",
    "                text = temp.copy()\n",
    "                text = ' '.join(text)\n",
    "                text = text.lower()\n",
    "            else:\n",
    "                pass\n",
    "        #STEMMER\n",
    "        if stemmer==True:\n",
    "            if lang == 'finnish':\n",
    "                snowball_stemmer = SnowballStemmer('finnish')\n",
    "                text = ' '.join([snowball_stemmer.stem(word) for word in text.split()])\n",
    "                \n",
    "            elif lang == 'eng':\n",
    "                snowball_stemmer = SnowballStemmer('english')\n",
    "                text = ' '.join([snowball_stemmer.stem(word) for word in text.split()])\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        if stop_words==True:\n",
    "            if lang == 'finnish':\n",
    "                stop_words = get_stop_words('finnish')\n",
    "                text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "            elif lang == 'zh':\n",
    "                stop_words = set(line.strip() for line in open('stopwords-zh.txt', encoding='utf8'))\n",
    "                text = list(jieba.cut_for_search(text))\n",
    "                text = ' '.join([word for word in text if word not in stop_words])\n",
    "            else:\n",
    "                stop_words = set(stopwords.words('english')).union(STOP_WORDS)\n",
    "                text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        \n",
    "        # For en-zh language pair use jieba for words cut\n",
    "        if lang == 'zh':\n",
    "            text = list(jieba.cut_for_search(text))\n",
    "        else:\n",
    "            # Convert to list from string\n",
    "            text = text.split()   \n",
    "\n",
    "        text = \" \".join(text)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(ref_trans, pontuation = True, lemmatize=True, stemmer=True, stop_words = True):\n",
    "    \n",
    "    if ref_trans == 'referece':\n",
    "        a,b,c = references_cs, references_de, scores_en_fi['reference']\n",
    "        d,e,f = scores_en_zh['reference'], references_ru, references_zh\n",
    "    elif ref_trans == 'translation':\n",
    "        a,b,c = translation_cs, translation_de, scores_en_fi['translation']\n",
    "        d,e,f = scores_en_zh['translation'], translation_ru, translation_zh\n",
    "        \n",
    "    ref_trans_cs = preprocessing(a,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_de = preprocessing(b,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_en_fi = preprocessing(c,'finnish', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_en_zh = preprocessing(d,'zh', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_ru = preprocessing(e,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_zh = preprocessing(f,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    out = ref_trans_cs, ref_trans_de, ref_trans_en_fi, ref_trans_en_zh, ref_trans_ru, ref_trans_zh\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f10ea7c27b4815b44e5ed147fcc800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cc42f824464783bc325c540533cb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae8150a71374d5a89d9f8ef601e0c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f4deb4a09d4435bdde08b5b1e73368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09495e4455e746bebcdb55947362bd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc187849e65447ab25f5f6c8a5ab98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49435680bc344e682129558da79be68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0acf302ad53403c8c7474c1e2f043a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce68363de9746dd8fdd3f83d292cea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439a61d8084b46f1b2ea76c52419ba71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b8effa6e4b47809f2bc4e93bd06222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e943f351fa42e498d45ef6fe9fd3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All parameters set to False\n",
    "\n",
    "references_cs1, references_de1, references_en_fi1, references_en_zh1, references_ru1, references_zh1 = prep(\n",
    "    'referece', pontuation = False, lemmatize=False, stemmer=False, stop_words = False)\n",
    "\n",
    "translation_cs1, translation_de1, translation_en_fi1, translation_en_zh1, translation_ru1, translation_zh1 = prep(\n",
    "    'translation', pontuation = False, lemmatize=False, stemmer=False, stop_words = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for evaluate ready metrics for all reference/translation pairs\n",
    "def chrf_metric(translation, references):\n",
    "    chrf_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = chrf.sentence_chrf([translation[i]], references[i])\n",
    "        chrf_metric.append(row)\n",
    "    return chrf_metric\n",
    "\n",
    "def gleu_metric(translation, references):\n",
    "    gleu_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = gleu.sentence_gleu([str(references[i]).split()], str(translation[i]).split(), min_len=1, max_len=2)\n",
    "        gleu_metric.append(row)\n",
    "    return gleu_metric\n",
    "def meteor_metric(translation, references):\n",
    "    meteor_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (meteor.meteor_score([translation[i]], references[i]))\n",
    "        meteor_metric.append(row)\n",
    "    return meteor_metric\n",
    "def bleu_metric(translation, references):\n",
    "    bleu_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (bleu.sentence_bleu([translation[i]], references[i]))\n",
    "        bleu_metric.append(row)\n",
    "    return bleu_metric\n",
    "\n",
    "def nist_metric(translation, references):\n",
    "    nist_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (nist.sentence_nist([translation[i]], references[i], n=1))\n",
    "        nist_metric.append(row)\n",
    "    return nist_metric\n",
    "def bert_metric(translation, references, lang):\n",
    "    P, R, bert_metric = bert.score(translation, references, lang=lang, verbose=True)\n",
    "    return bert_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(scores, b = False):\n",
    "    chf = scores['z-score'].corr(scores['chf'])\n",
    "    gleu = scores['z-score'].corr(scores['gleu'])\n",
    "    meteor = scores['z-score'].corr(scores['meteor'])\n",
    "    bleu = scores['z-score'].corr(scores['bleu'])\n",
    "   # nist = scores['z-score'].corr(scores['nist'])\n",
    "    if b == True:\n",
    "        bert = scores['z-score'].corr(scores['bert'])\n",
    "        corr = [chf, gleu, meteor, bleu, bert]\n",
    "    else:\n",
    "        bert = 0\n",
    "        corr = [chf, gleu, meteor, bleu]\n",
    "   \n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(t1,t2,t3,t4,t5,t6, r1,r2,r3,r4,r5,r6, b = False):\n",
    "    chf_cs = chrf_metric(t1, r1)\n",
    "    scores_cs['chf'] = chf_cs\n",
    "    chf_de = chrf_metric(t2, r2)\n",
    "    scores_de['chf'] = chf_de\n",
    "    chf_en_fi = chrf_metric(t3, r3)\n",
    "    scores_en_fi['chf'] = chf_en_fi\n",
    "    chf_en_zh = chrf_metric(t4, r4)\n",
    "    scores_en_zh['chf'] = chf_en_zh\n",
    "    chf_ru = chrf_metric(t5, r5)\n",
    "    scores_ru['chf'] = chf_ru\n",
    "    chf_zh = chrf_metric(t6, r6)\n",
    "    scores_zh['chf'] = chf_zh\n",
    "    \n",
    "    gleu_cs = gleu_metric(t1, r1)\n",
    "    scores_cs['gleu'] = gleu_cs\n",
    "    gleu_de = gleu_metric(t2, r2)\n",
    "    scores_de['gleu'] = gleu_de\n",
    "    gleu_en_fi = gleu_metric(t3, r3)\n",
    "    scores_en_fi['gleu'] = gleu_en_fi\n",
    "    gleu_en_zh = gleu_metric(t4, r4)\n",
    "    scores_en_zh['gleu'] = gleu_en_zh\n",
    "    gleu_ru = gleu_metric(t5, r5)\n",
    "    scores_ru['gleu'] = gleu_ru\n",
    "    gleu_zh = gleu_metric(t6, r6)\n",
    "    scores_zh['gleu'] = gleu_zh\n",
    "    \n",
    "    meteor_cs = meteor_metric(t1, r1)\n",
    "    scores_cs['meteor'] = meteor_cs\n",
    "    meteor_de = meteor_metric(t2, r2)\n",
    "    scores_de['meteor'] = meteor_de\n",
    "    meteor_en_fi = meteor_metric(t3, r3)\n",
    "    scores_en_fi['meteor'] = meteor_en_fi\n",
    "    meteor_en_zh = meteor_metric(t4, r4)\n",
    "    scores_en_zh['meteor'] = meteor_en_zh\n",
    "    meteor_ru = meteor_metric(translation_ru, references_ru)\n",
    "    scores_ru['meteor'] = meteor_ru\n",
    "    meteor_zh = meteor_metric(translation_zh, references_zh)\n",
    "    scores_zh['meteor'] = meteor_zh\n",
    "    \n",
    "    bleu_cs = bleu_metric(t1, r1)\n",
    "    scores_cs['bleu'] = bleu_cs\n",
    "    bleu_de = bleu_metric(t2, r2)\n",
    "    scores_de['bleu'] = bleu_de\n",
    "    bleu_en_fi = bleu_metric(t3, r3)\n",
    "    scores_en_fi['bleu'] = bleu_en_fi\n",
    "    bleu_en_zh = bleu_metric(t4, r4)\n",
    "    scores_en_zh['bleu'] = bleu_en_zh\n",
    "    bleu_ru = bleu_metric(t5, r5)\n",
    "    scores_ru['bleu'] = bleu_ru\n",
    "    bleu_zh = bleu_metric(t6, r6)\n",
    "    scores_zh['bleu'] = bleu_zh\n",
    "    \n",
    "#     nist_cs = nist_metric(t1, r1)\n",
    "#     scores_cs['nist'] = nist_cs\n",
    "#     nist_de = nist_metric(t2, r2)\n",
    "#     scores_de['nist'] = nist_de\n",
    "#     nist_en_fi = nist_metric(t3, r3)\n",
    "#     scores_en_fi['nist'] = nist_en_fi\n",
    "#     nist_en_zh = nist_metric(t4, r4)\n",
    "#     scores_en_zh['nist'] = nist_en_zh\n",
    "#     nist_ru = nist_metric(t5, r5)\n",
    "#     scores_ru['nist'] = nist_ru\n",
    "#     nist_zh = nist_metric(t6, r6)\n",
    "#     scores_zh['nist'] = nist_zh\n",
    "    \n",
    "    if b == True:\n",
    "        bert_cs = bert_metric(t1, r1, 'en')\n",
    "        scores_cs['bert'] = bert_cs\n",
    "        bert_de = bert_metric(t2, r2, 'en')\n",
    "        scores_de['bert'] = bert_de\n",
    "        bert_en_fi = bert_metric(t3, r3, 'others')\n",
    "        scores_en_fi['bert'] = bert_en_fi\n",
    "        bert_en_zh = bert_metric(t4, r4, 'zh')\n",
    "        scores_en_zh['bert'] = bert_en_zh\n",
    "        bert_ru = bert_metric(t5, r5, 'en')\n",
    "        scores_ru['bert'] = bert_ru\n",
    "        bert_zh = bert_metric(t6, r6, 'en')\n",
    "        scores_zh['bert'] = bert_zh\n",
    "        \n",
    "        columns = ['chrf', 'gleu', 'meteor', 'bleu', 'bert']\n",
    "        \n",
    "    else:\n",
    "        columns = ['chrf', 'gleu', 'meteor', 'bleu']\n",
    "\n",
    "    corr_cs = corr(scores_cs, b = b)\n",
    "    corr_de = corr(scores_de, b = b)\n",
    "    corr_en_fi = corr(scores_en_fi, b =b)\n",
    "    corr_en_zh = corr(scores_en_zh, b = b)\n",
    "    corr_ru = corr(scores_ru, b = b)\n",
    "    corr_zh = corr(scores_zh, b = b)\n",
    "    \n",
    "    data = []\n",
    "    index = ['scores_cs', 'scores_de', 'scores_en_fi', 'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "    correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "    correlation.iloc[0] = corr_cs\n",
    "    correlation.iloc[1] = corr_de\n",
    "    correlation.iloc[2] = corr_en_fi\n",
    "    correlation.iloc[3] = corr_en_zh\n",
    "    correlation.iloc[4] = corr_ru\n",
    "    correlation.iloc[5] = corr_zh\n",
    "    return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.462239</td>\n",
       "      <td>0.427909</td>\n",
       "      <td>0.439981</td>\n",
       "      <td>0.468781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.341172</td>\n",
       "      <td>0.310139</td>\n",
       "      <td>0.308153</td>\n",
       "      <td>0.346757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.611567</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.491475</td>\n",
       "      <td>0.619928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.468428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361388</td>\n",
       "      <td>0.333465</td>\n",
       "      <td>0.336711</td>\n",
       "      <td>0.367557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.341228</td>\n",
       "      <td>0.317931</td>\n",
       "      <td>0.326447</td>\n",
       "      <td>0.351904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chrf      gleu    meteor      bleu\n",
       "scores_cs     0.462239  0.427909  0.439981  0.468781\n",
       "scores_de     0.341172  0.310139  0.308153  0.346757\n",
       "scores_en_fi  0.611567  0.494636  0.491475  0.619928\n",
       "scores_en_zh  0.423398  0.449157  0.453092  0.468428\n",
       "scores_ru     0.361388  0.333465  0.336711  0.367557\n",
       "scores_zh     0.341228  0.317931  0.326447  0.351904"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate baseline results for all ready metrics\n",
    "create_table(translation_cs1, translation_de1, translation_en_fi1, translation_en_zh1, translation_ru1, translation_zh1,\n",
    "             references_cs1, references_de1, references_en_fi1, references_en_zh1, references_ru1, references_zh1,\n",
    "             b = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077e6e111559439697cbab6229855330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994d0ebb747c4689a476f3a8be09f9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7875c86e8341938f6ac6d7a2a9b257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f2119e1e8641dcac5986349841b97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c880faedc5247f98b36d8b4d9c61332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec04fe899564b0e9cc59c39753a3a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d0de9494a843549002434f8f4ff1d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8958658ac1413baae70d1289d97b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf57c6a0e224fd7b922c2aadc5f1932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456b7cb1ee2047b5b15a1ef9288aa6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b445e300ad06404595b7fb20331f0c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7918d91e4e01430ab00f54783e40407f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Punctuation == True\n",
    "\n",
    "references_cs2, references_de2, references_en_fi2, references_en_zh2,references_ru2, references_zh2 = prep(\n",
    "    'referece', pontuation = True, lemmatize=False, stemmer=False, stop_words = False)\n",
    "\n",
    "translation_cs2, translation_de2, translation_en_fi2, translation_en_zh2, translation_ru2, translation_zh2 = prep(\n",
    "    'translation', pontuation = True, lemmatize=False, stemmer=False, stop_words = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.460175</td>\n",
       "      <td>0.442928</td>\n",
       "      <td>0.459244</td>\n",
       "      <td>0.46626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.339221</td>\n",
       "      <td>0.323857</td>\n",
       "      <td>0.323407</td>\n",
       "      <td>0.343768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.606508</td>\n",
       "      <td>0.521099</td>\n",
       "      <td>0.516653</td>\n",
       "      <td>0.616161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.419761</td>\n",
       "      <td>0.44232</td>\n",
       "      <td>0.451714</td>\n",
       "      <td>0.475039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.35807</td>\n",
       "      <td>0.341896</td>\n",
       "      <td>0.336711</td>\n",
       "      <td>0.362122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.337752</td>\n",
       "      <td>0.329073</td>\n",
       "      <td>0.326447</td>\n",
       "      <td>0.347637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chrf      gleu    meteor      bleu\n",
       "scores_cs     0.460175  0.442928  0.459244   0.46626\n",
       "scores_de     0.339221  0.323857  0.323407  0.343768\n",
       "scores_en_fi  0.606508  0.521099  0.516653  0.616161\n",
       "scores_en_zh  0.419761   0.44232  0.451714  0.475039\n",
       "scores_ru      0.35807  0.341896  0.336711  0.362122\n",
       "scores_zh     0.337752  0.329073  0.326447  0.347637"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate results for all ready metrics with deletion of Punctuation\n",
    "create_table(translation_cs2, translation_de2, translation_en_fi2, translation_en_zh2, translation_ru2, translation_zh2,\n",
    "             references_cs2, references_de2, references_en_fi2, references_en_zh2, references_ru2, references_zh2,\n",
    "             b = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60b628560fe4c6b8a1e0c422488035d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8bd1280f1f444ab9cf9e86b201fa75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2093d478fe649df82c1081573e58510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fd9b4050cd4cc08b464baf3721d970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8387cc56db034791ac69217c1e7a64f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07158008f4a46b9a6ec467a9c160f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedfd6f9ef764151b565c17561bca202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbebfc75e39a4bd194da367a05c6dea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e1343cabe64c36a387f78e3133b331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2771b074f746451bae2f0a2389917175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a7f0413bd9469ba4451c90be175ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25cf1a643214ab484fa7e8686f73db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize == True\n",
    "\n",
    "references_cs3, references_de3, references_en_fi3, references_en_zh3,references_ru3, references_zh3 = prep(\n",
    "    'referece', pontuation = False, lemmatize=True, stemmer=False, stop_words = False)\n",
    "\n",
    "translation_cs3, translation_de3, translation_en_fi3, translation_en_zh3, translation_ru3, translation_zh3 = prep(\n",
    "    'translation', pontuation = False, lemmatize=True, stemmer=False, stop_words = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.461182</td>\n",
       "      <td>0.42928</td>\n",
       "      <td>0.44041</td>\n",
       "      <td>0.468664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.339801</td>\n",
       "      <td>0.311003</td>\n",
       "      <td>0.308517</td>\n",
       "      <td>0.345696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.596299</td>\n",
       "      <td>0.525408</td>\n",
       "      <td>0.521339</td>\n",
       "      <td>0.60642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.468428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361224</td>\n",
       "      <td>0.33507</td>\n",
       "      <td>0.336711</td>\n",
       "      <td>0.366839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.340611</td>\n",
       "      <td>0.318608</td>\n",
       "      <td>0.326447</td>\n",
       "      <td>0.350394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chrf      gleu    meteor      bleu\n",
       "scores_cs     0.461182   0.42928   0.44041  0.468664\n",
       "scores_de     0.339801  0.311003  0.308517  0.345696\n",
       "scores_en_fi  0.596299  0.525408  0.521339   0.60642\n",
       "scores_en_zh  0.423398  0.449157  0.453092  0.468428\n",
       "scores_ru     0.361224   0.33507  0.336711  0.366839\n",
       "scores_zh     0.340611  0.318608  0.326447  0.350394"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-calculate all ready metrics with Lemmatize == True\n",
    "create_table(translation_cs3, translation_de3, translation_en_fi3, translation_en_zh3, translation_ru3, translation_zh3,\n",
    "             references_cs3, references_de3, references_en_fi3, references_en_zh3, references_ru3, references_zh3,\n",
    "             b = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66099fe22d354aadb999f1b19c6fc5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d890be94d3c42e79a831ef141cd135f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08ca109ce3d410183d79eac71784198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932af97618b34a3a882ee69615821382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d16b21f2e9a4cafa53d20cefb42f080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d358e6123f4bb7973d4a776f9a54ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ee84f623664280b65265f2905fae5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d80c94421c14f72bf190fe697961c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7456c5c1d6524f61b4367c6146671edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3138e14a5c674fd992ff9498675bb14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185086a842304a98900fee2cf1dd06ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229921632679425ead9fe13a9812fe62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Stemmer == True\n",
    "\n",
    "references_cs4, references_de4, references_en_fi4, references_en_zh4,references_ru4, references_zh4 = prep(\n",
    "    'referece', pontuation = False, lemmatize=False, stemmer=True, stop_words = False)\n",
    "\n",
    "translation_cs4, translation_de4, translation_en_fi4, translation_en_zh4, translation_ru4, translation_zh4 = prep(\n",
    "    'translation', pontuation = False, lemmatize=False, stemmer=True, stop_words = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.458551</td>\n",
       "      <td>0.433943</td>\n",
       "      <td>0.440132</td>\n",
       "      <td>0.466033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.33548</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>0.310658</td>\n",
       "      <td>0.342397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.595025</td>\n",
       "      <td>0.510169</td>\n",
       "      <td>0.506616</td>\n",
       "      <td>0.609784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.468428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.360056</td>\n",
       "      <td>0.338979</td>\n",
       "      <td>0.336711</td>\n",
       "      <td>0.366964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.342474</td>\n",
       "      <td>0.322487</td>\n",
       "      <td>0.326447</td>\n",
       "      <td>0.353436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chrf      gleu    meteor      bleu\n",
       "scores_cs     0.458551  0.433943  0.440132  0.466033\n",
       "scores_de      0.33548  0.312284  0.310658  0.342397\n",
       "scores_en_fi  0.595025  0.510169  0.506616  0.609784\n",
       "scores_en_zh  0.423398  0.449157  0.453092  0.468428\n",
       "scores_ru     0.360056  0.338979  0.336711  0.366964\n",
       "scores_zh     0.342474  0.322487  0.326447  0.353436"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-calculate all ready metrics with Stemmer == True\n",
    "create_table(translation_cs4, translation_de4, translation_en_fi4, translation_en_zh4, translation_ru4, translation_zh4,\n",
    "             references_cs4, references_de4, references_en_fi4, references_en_zh4, references_ru4, references_zh4,\n",
    "             b = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d90e6d673df41b79b076ed9b7b4fbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8972a94e425422fa581d9fd6d9c580c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088dcfe7c8c94aac8bacabc2fb6ab0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b841ded13441f78f133ae943ac85d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472378abfb52400c9434fdb4772597d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b79691aaff94ca39db9477090ad0d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18a31e10b234d858a1f1e8e7306461b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f01404c6450425497886e10f703643b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7812245be240dda2e87c8adf64856d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992c8ae924934d33ad1c70f4f1157286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51fc6015fe240efa06ba07ed2e82d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c723596cee1044a5bf630fbd40ff522d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Stop_words == True\n",
    "\n",
    "references_cs5, references_de5, references_en_fi5, references_en_zh5, references_ru5, references_zh5 = prep(\n",
    "    'referece', pontuation = False, lemmatize=False, stemmer=False, stop_words = True)\n",
    "\n",
    "translation_cs5, translation_de5, translation_en_fi5, translation_en_zh5, translation_ru5, translation_zh5 = prep(\n",
    "    'translation', pontuation = False, lemmatize=False, stemmer=False, stop_words = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.462193</td>\n",
       "      <td>0.427878</td>\n",
       "      <td>0.439901</td>\n",
       "      <td>0.468756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.34117</td>\n",
       "      <td>0.310134</td>\n",
       "      <td>0.308149</td>\n",
       "      <td>0.346754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.611555</td>\n",
       "      <td>0.494621</td>\n",
       "      <td>0.49147</td>\n",
       "      <td>0.619918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423409</td>\n",
       "      <td>0.449227</td>\n",
       "      <td>0.453161</td>\n",
       "      <td>0.468476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361388</td>\n",
       "      <td>0.333425</td>\n",
       "      <td>0.336711</td>\n",
       "      <td>0.36755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.341249</td>\n",
       "      <td>0.317942</td>\n",
       "      <td>0.326447</td>\n",
       "      <td>0.351916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chrf      gleu    meteor      bleu\n",
       "scores_cs     0.462193  0.427878  0.439901  0.468756\n",
       "scores_de      0.34117  0.310134  0.308149  0.346754\n",
       "scores_en_fi  0.611555  0.494621   0.49147  0.619918\n",
       "scores_en_zh  0.423409  0.449227  0.453161  0.468476\n",
       "scores_ru     0.361388  0.333425  0.336711   0.36755\n",
       "scores_zh     0.341249  0.317942  0.326447  0.351916"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-calculate all ready metrics with stop_words == True\n",
    "create_table(translation_cs5, translation_de5, translation_en_fi5, translation_en_zh5, translation_ru5, translation_zh5,\n",
    "             references_cs5, references_de5, references_en_fi5, references_en_zh5, references_ru5, references_zh5,\n",
    "             b = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea731112b7e74d5aa546f02227be7bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64051baf65c43deb946284449132139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a888158362774551bf4f9aaec4962fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c0614378ac499cb974d7b41f9165a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ed149d78ba4fda8cd93d12aabb5412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91991b7d9e674fc3b6cf34384da61aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77f881273e442d49f2bd502dfeb9f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab3e80c68634db78e40f56efac85330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13a6b5bd1fa4f1893fb9c3da56976b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfced95b4c9644e4809e1d9468bb6e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b840e8b5784588a15551e06074fa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd344793e8b14c908774e211faef217b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All parameters of pre-processing set to  True except Stemmer\n",
    "\n",
    "references_cs6, references_de6, references_en_fi6, references_en_zh6, references_ru6, references_zh6 = prep(\n",
    "    'referece', pontuation = True, lemmatize=True, stemmer=False, stop_words = True)\n",
    "\n",
    "translation_cs6, translation_de6, translation_en_fi6, translation_en_zh6, translation_ru6, translation_zh6 = prep(\n",
    "    'translation', pontuation = True, lemmatize=True, stemmer=False, stop_words = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b951a07abe4ee4a7a85cbea43b01d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ec0735e0a94738a2bc96d16e50eb4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=182.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 2524.76 seconds, 4.59 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182300e3c5d14d82a4b6f954d38a99ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=375.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747a3c59d27146938082ac8c4738489c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=340.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 3985.45 seconds, 5.45 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555fc6c19f354d16b04dbc3a17345962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=147.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec46197954d45a8a6ba75ff1760c6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 674.12 seconds, 10.01 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c1230c337f4dd490b54ebf444d00a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=191.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088a0398bca64c8cb0885d15759f7984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=160.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting recall to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 1241.31 seconds, 8.23 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e990356ac1cb46578ca6778c7a5860ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=323.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32cb024a9074ee9a2a5f8a2ce35421f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 3852.89 seconds, 4.67 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4417f66c1b948cab53206967fac2081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=440.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9f186d183448d4894a592cd4731dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n",
      "Warning: Empty reference sentence detected; setting recall to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done in 4973.61 seconds, 5.31 sentences/sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "      <th>bert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.458563</td>\n",
       "      <td>0.444786</td>\n",
       "      <td>0.460774</td>\n",
       "      <td>0.465282</td>\n",
       "      <td>0.567269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.337663</td>\n",
       "      <td>0.326861</td>\n",
       "      <td>0.325655</td>\n",
       "      <td>0.342394</td>\n",
       "      <td>0.421566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.590391</td>\n",
       "      <td>0.560004</td>\n",
       "      <td>0.556457</td>\n",
       "      <td>0.603164</td>\n",
       "      <td>0.615133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.419763</td>\n",
       "      <td>0.442372</td>\n",
       "      <td>0.451762</td>\n",
       "      <td>0.475075</td>\n",
       "      <td>0.541409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.357554</td>\n",
       "      <td>0.345029</td>\n",
       "      <td>0.336711</td>\n",
       "      <td>0.360968</td>\n",
       "      <td>0.418593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.3367</td>\n",
       "      <td>0.33273</td>\n",
       "      <td>0.326447</td>\n",
       "      <td>0.345333</td>\n",
       "      <td>0.416299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chrf      gleu    meteor      bleu      bert\n",
       "scores_cs     0.458563  0.444786  0.460774  0.465282  0.567269\n",
       "scores_de     0.337663  0.326861  0.325655  0.342394  0.421566\n",
       "scores_en_fi  0.590391  0.560004  0.556457  0.603164  0.615133\n",
       "scores_en_zh  0.419763  0.442372  0.451762  0.475075  0.541409\n",
       "scores_ru     0.357554  0.345029  0.336711  0.360968  0.418593\n",
       "scores_zh       0.3367   0.33273  0.326447  0.345333  0.416299"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-calculate all ready metrics with all parameters set to True\n",
    "create_table(translation_cs6, translation_de6, translation_en_fi6, translation_en_zh6, translation_ru6, translation_zh6,\n",
    "             references_cs6, references_de6, references_en_fi6, references_en_zh6, references_ru6, references_zh6,\n",
    "             b = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cosine similarities for sentences using word embeddings\n",
    " - we use pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_cos(ref_trans, pontuation = True, lemmatize=True, stemmer=True, stop_words = True):\n",
    "    \n",
    "    if ref_trans == 'referece':\n",
    "        a,b,c = scores_cs['reference'], scores_de['reference'], scores_en_fi['reference']\n",
    "        d,e,f = scores_en_zh['reference'], scores_ru['reference'].astype(str), scores_zh['reference']\n",
    "    elif ref_trans == 'translation':\n",
    "        a,b,c = scores_cs['translation'], scores_de['translation'], scores_en_fi['translation']\n",
    "        d,e,f = scores_en_zh['translation'], scores_ru['translation'].astype(str), scores_zh['translation']\n",
    "        \n",
    "    ref_trans_cs = preprocessing(a,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_de = preprocessing(b,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_en_fi = preprocessing(c,'finnish', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_en_zh = preprocessing(d,'zh', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_ru = preprocessing(e,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_zh = preprocessing(f,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    out = ref_trans_cs, ref_trans_de, ref_trans_en_fi, ref_trans_en_zh, ref_trans_ru, ref_trans_zh\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80b1a6cc02a42a6ba7108e3de526c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb8abf5f494c4ca09751701c4e3210b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842cbb15276b477eae3a967553316b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c2d8dd1bf84a0f97a7e600fb5c9537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1464cc57054aaca876994f2fb5416d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c4cabefb7445fb9eeb5c2b4ffff46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a526452b834100bf8e1ef50ac64785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76921363539f4ca9a1f0c8f96e0befbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1e6a8df55b44e286300d6414948a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3cf0165d3454a02a363117ded432f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab10b80739f4d5180758be9425454e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52d1fd221314b77afe937981ac48ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All parameters set to False\n",
    "\n",
    "references_cs10, references_de10, references_en_fi10, references_en_zh10, references_ru10, references_zh10 = prep_cos(\n",
    "    'referece', pontuation = False, lemmatize=False, stemmer=False, stop_words = False)\n",
    "\n",
    "translation_cs10, translation_de10, translation_en_fi10, translation_en_zh10, translation_ru10, translation_zh10 = prep_cos(\n",
    "    'translation', pontuation = False, lemmatize=False, stemmer=False, stop_words = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7a636f169e467f9519c32372ce4c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a6cac0f3cd4f208caa3011d3182674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43dd0e09459412c8a976f00bf12ddd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1969bf393081410c81f3fe788e3aaeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b8977877e24e79b00adcb13645a734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbacfedc9afa4298b4378907de16ea8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bc2a515ba942b3ae4c2f633d6b6cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec92230620e4c1e9ddd80a1c726821a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfb889b09604540896e127ee70fcdd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3a30fdc8b449889bc51503862b3252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0bf521f1b64a649e1801cdf8d03c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3167ee9d86d46f8b7e2021c2159f120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All parameters of pre-processing set to  True except Stemmer\n",
    "\n",
    "references_cs11, references_de11, references_en_fi11, references_en_zh11, references_ru11, references_zh11 = prep_cos(\n",
    "    'referece', pontuation = True, lemmatize=True, stemmer=False, stop_words = True)\n",
    "\n",
    "translation_cs11, translation_de11, translation_en_fi11, translation_en_zh11, translation_ru11, translation_zh11 = prep_cos(\n",
    "    'translation', pontuation = True, lemmatize=True, stemmer=False, stop_words = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english stopwords\n",
    "english_stop_words = set(stopwords.words('english')).union(STOP_WORDS)\n",
    "\n",
    "# chinese stopwords\n",
    "#stopwords_zh = codecs.open('stopwords-zh.txt', 'r', 'utf-8').read().split(',')\n",
    "stopwords_zh = set(line.strip() for line in open('stopwords-zh.txt', encoding='utf8'))\n",
    "\n",
    "# finnish stopwords\n",
    "stop_words_fi = get_stop_words('finnish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of words\n",
    "\n",
    "def words_count(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "   \n",
    "    # delete stop words\n",
    "    tokens = list(filter(lambda x: x not in english_stop_words, tokens))\n",
    "    \n",
    "    # lemmatize the words WordNetLemmatizer from nlkt\n",
    "    # this made Pearson correlation lower - so was commented\n",
    "    \n",
    "    # tokens = list(map(lambda x: nltk.WordNetLemmatizer().lemmatize(x), tokens))\n",
    "    \n",
    "    # With spacy lemmatizer (worked better than nltk)\n",
    "    # it is commented because it made correlation lower\n",
    "    # tokens = list(map(lambda x: [token.lemma_ for token in nlp(x)], tokens))\n",
    "    # tokens = list(itertools.chain(*tokens))\n",
    "    \n",
    "    return list(Counter(tokens).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of words\n",
    "\n",
    "def words_count_zh(text):\n",
    "#     # Tokenize\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # delete stop words\n",
    "    tokens = list(filter(lambda x: x not in stopwords_zh, tokens))\n",
    "    return list(Counter(tokens).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained GloVe (Global Vectors for Word Representation) word vectors.\n",
    "# For cs, de, ru, zh that translated to english\n",
    "# 6B tokens, 400K vocab, (300d version).\n",
    "# Download file from https://www.kaggle.com/thanakomsn/glove6b300dtxt\n",
    "# to a folder with this jupiter notebook (size 1Gb)\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "# Download glove.6B.300d.txt to a folder with this jupiter notebook\n",
    "word_to_vec_map = read_glove_vecs('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese word vector\n",
    "# Download word vectors file from https://www.kaggle.com/kerneler/starter-sgns-merge-word-18e5b7b5-9/execution?select=sgns.merge.word\n",
    "# file to a folder with this jupiter notebook (size 3.5Gb)\n",
    "word_to_vec_zh = read_glove_vecs('sgns.merge.word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could not find glove nodel for finnish,\n",
    "# so will work with finnish language separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for calculating cosine similarity\n",
    "scores_cs['Cosine_similarity'], scores_de['Cosine_similarity'] = 0, 0\n",
    "scores_ru['Cosine_similarity'], scores_zh['Cosine_similarity'] = 0, 0\n",
    "scores_en_fi['Cosine_similarity'], scores_en_zh['Cosine_similarity'] = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cosine similarity between two sentences (reference and translation)\n",
    "# Use different pre-trained word embeddings:\n",
    "# GloVe - for cs, de, ru, zh that translated to english\n",
    "# 'sgns.merge.word' - for en-zh pair\n",
    "def cos_s(ref_list, trans_list, scores):\n",
    "    for doc in range(len(scores)):\n",
    "        ref_embeddings = np.zeros((len(scores[doc]),300))\n",
    "        tr_embeddings = np.zeros((len(scores[doc]),300))\n",
    "\n",
    "        norms_doc_embeddings_tr = np.zeros((len(trans_list[doc]),1))\n",
    "        norms_doc_embeddings_ref = np.zeros((len(ref_list[doc]),1))\n",
    "\n",
    "        Cosine_similarity = []\n",
    "\n",
    "        for i in tqdm(range(len(trans_list[doc]))):\n",
    "            if doc == 4:\n",
    "                words_freq = words_count_zh(trans_list[doc][i])\n",
    "                doc_embeddings = np.zeros(word_to_vec_zh[\"a\"].shape)\n",
    "\n",
    "            else:\n",
    "                words_freq = words_count(trans_list[doc][i])\n",
    "                doc_embeddings = np.zeros(word_to_vec_map[\"a\"].shape)\n",
    "            num_words = 0\n",
    "            for word_freq in words_freq:\n",
    "                word = word_freq[0]\n",
    "                freq = word_freq[1]\n",
    "                try:\n",
    "                    #adding word embeddings for each word in the document\n",
    "                    if doc == 4:\n",
    "                        doc_embeddings += (word_to_vec_zh[word] * freq)\n",
    "                    else:\n",
    "                        doc_embeddings += (word_to_vec_map[word] * freq)\n",
    "                    num_words += freq\n",
    "                except:\n",
    "                    continue\n",
    "            try:\n",
    "                # doing average\n",
    "                doc_embeddings /= num_words\n",
    "            except:\n",
    "                print(\"divide by zero encountered for article at index \"+str(i))\n",
    "                continue\n",
    "            norms_doc_embeddings_tr[i,:] = np.sqrt(np.dot(doc_embeddings,doc_embeddings))\n",
    "            tr_embeddings[i,:] = doc_embeddings\n",
    "\n",
    "\n",
    "            if doc == 4:\n",
    "                words_freq = words_count_zh(ref_list[doc][i])\n",
    "                doc_embeddings = np.zeros(word_to_vec_zh[\"a\"].shape)\n",
    "            else:\n",
    "                words_freq = words_count(ref_list[doc][i])\n",
    "                doc_embeddings = np.zeros(word_to_vec_map[\"a\"].shape)\n",
    "            num_words = 0\n",
    "            for word_freq in words_freq:\n",
    "                word = word_freq[0]\n",
    "                freq = word_freq[1]\n",
    "                try:\n",
    "                    #adding word embeddings for each word in the document\n",
    "                    if doc == 4:\n",
    "                        doc_embeddings += (word_to_vec_zh[word] * freq)\n",
    "\n",
    "                    else:\n",
    "                        doc_embeddings += (word_to_vec_map[word] * freq)\n",
    "                    num_words += freq\n",
    "                except:\n",
    "                    continue\n",
    "            try:\n",
    "                # doing average\n",
    "                doc_embeddings /= num_words\n",
    "            except:\n",
    "                print(\"divide by zero encountered for article at index \"+str(i))\n",
    "                continue\n",
    "            norms_doc_embeddings_ref[i,:] = np.sqrt(np.dot(doc_embeddings,doc_embeddings))\n",
    "            ref_embeddings[i,:] = doc_embeddings\n",
    "\n",
    "            # Calculate cosine similarity using dot product of two vectors\n",
    "            # and norms of vectors\n",
    "\n",
    "            #  The cosine similarity depends on the angle between  vectors .\n",
    "            #  If  vectors  are very similar, their cosine similarity will be close to 1\n",
    "            norm_prods = norms_doc_embeddings_ref[i] * norms_doc_embeddings_tr[i]\n",
    "            dot_prod = np.dot(ref_embeddings[i], tr_embeddings[i].reshape(300,1))\n",
    "            cos_similarity = dot_prod / norm_prods\n",
    "\n",
    "            Cosine_similarity.append(float(cos_similarity))\n",
    "\n",
    "        scores[doc]['Cosine_similarity'] = pd.Series(Cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5235932dffa247978ead28e240208d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5d6776b6644d009caac7bb75c7a39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9bac941c7b47588117b5d3c637be8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306f4929f2d943728557442384239efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726aad3f714e4d468c9358b38b0fd307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lists with languages to work with\n",
    "ref_list = [references_cs10, references_de10, references_ru10, references_zh10, references_en_zh10]\n",
    "trans_list = [translation_cs10, translation_de10, translation_ru10, translation_zh10, translation_en_zh10]\n",
    "scores = [scores_cs, scores_de, scores_ru, scores_zh, scores_en_zh]\n",
    "# Calculate cosine similarity \n",
    "cos_s(ref_list, trans_list, scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_new(scores):\n",
    "    \n",
    "    cos = scores['z-score'].corr(scores['Cosine_similarity'])\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cs_new = corr_new(scores_cs)\n",
    "corr_de_new = corr_new(scores_de)\n",
    "corr_ru_new = corr_new(scores_ru)\n",
    "corr_zh_new = corr_new(scores_zh)\n",
    "\n",
    "corr_en_zh_new = corr_new(scores_en_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['Cosine_similarity (w/o stopwords)']\n",
    "data = []\n",
    "columns = ['scores_cs', 'scores_de',  'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "correlation.iloc[:,0] = corr_cs_new\n",
    "correlation.iloc[:,1] = corr_de_new\n",
    "correlation.iloc[:,2] = corr_en_zh_new\n",
    "\n",
    "correlation.iloc[:,3] = corr_ru_new\n",
    "correlation.iloc[:,4] = corr_zh_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores_cs</th>\n",
       "      <th>scores_de</th>\n",
       "      <th>scores_en_zh</th>\n",
       "      <th>scores_ru</th>\n",
       "      <th>scores_zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cosine_similarity (w/o stopwords)</th>\n",
       "      <td>0.368199</td>\n",
       "      <td>0.290665</td>\n",
       "      <td>0.396741</td>\n",
       "      <td>0.304872</td>\n",
       "      <td>0.271934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   scores_cs scores_de scores_en_zh scores_ru  \\\n",
       "Cosine_similarity (w/o stopwords)   0.368199  0.290665     0.396741  0.304872   \n",
       "\n",
       "                                  scores_zh  \n",
       "Cosine_similarity (w/o stopwords)  0.271934  "
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate correlation between z-score and cosine_similarity columns\n",
    "# for all language pairs except finnish\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b144f7751234ce0acfe59387028003a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4062fbf572f145fc9e970764f87c6251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e18c0f28f44c89922038e9e315a86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5befa3e6f6f44e3c9fee55167ebe283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ffe83f0fe3434f9171125959b1f573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lists with pre-processed series to work with\n",
    "# All parameters of pre-processing set to True except Stemmer\n",
    "ref_list = [references_cs11, references_de11, references_ru11, references_zh11, references_en_zh11]\n",
    "trans_list = [translation_cs11, translation_de11, translation_ru11, translation_zh11, translation_en_zh11]\n",
    "scores = [scores_cs, scores_de, scores_ru, scores_zh, scores_en_zh]\n",
    "# Calculate cosine similarity (without lemmatizationm removing stop-words and )\n",
    "cos_s(ref_list, trans_list, scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cs_new = corr_new(scores_cs)\n",
    "corr_de_new = corr_new(scores_de)\n",
    "corr_ru_new = corr_new(scores_ru)\n",
    "corr_zh_new = corr_new(scores_zh)\n",
    "corr_en_zh_new = corr_new(scores_en_zh)\n",
    "index = ['Cosine_similarity (pre-processing)']\n",
    "data = []\n",
    "columns = ['scores_cs', 'scores_de',  'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "correlation.iloc[:,0] = corr_cs_new\n",
    "correlation.iloc[:,1] = corr_de_new\n",
    "correlation.iloc[:,2] = corr_en_zh_new\n",
    "\n",
    "correlation.iloc[:,3] = corr_ru_new\n",
    "correlation.iloc[:,4] = corr_zh_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores_cs</th>\n",
       "      <th>scores_de</th>\n",
       "      <th>scores_en_zh</th>\n",
       "      <th>scores_ru</th>\n",
       "      <th>scores_zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cosine_similarity (pre-processing)</th>\n",
       "      <td>0.360295</td>\n",
       "      <td>0.287918</td>\n",
       "      <td>0.396771</td>\n",
       "      <td>0.307792</td>\n",
       "      <td>0.256307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    scores_cs scores_de scores_en_zh  \\\n",
       "Cosine_similarity (pre-processing)   0.360295  0.287918     0.396771   \n",
       "\n",
       "                                   scores_ru scores_zh  \n",
       "Cosine_similarity (pre-processing)  0.307792  0.256307  "
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate correlation between z-score and cosine_similarity columns\n",
    "# for all language pairs except finnish \n",
    "# All parameters of pre-processing set to True except Stemmer\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict for test-set (except Finnish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cs_test = pd.read_csv(\"testset/cs-en/scores.csv\")\n",
    "scores_de_test = pd.read_csv(\"testset/de-en/scores.csv\")\n",
    "scores_en_fi_test = pd.read_csv(\"testset/en-fi/scores.csv\")\n",
    "scores_en_zh_test = pd.read_csv(\"testset/en-zh/scores.csv\")\n",
    "scores_ru_test = pd.read_csv(\"testset/ru-en/scores.csv\")\n",
    "scores_zh_test = pd.read_csv(\"testset/zh-en/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(ref_trans, pontuation = True, lemmatize=True, stemmer=True, stop_words = True):\n",
    "    \n",
    "    if ref_trans == 'referece':\n",
    "        a,b,c = scores_cs_test['reference'], scores_de_test['reference'], scores_en_fi_test['reference']\n",
    "        d,e,f = scores_en_zh_test['reference'], scores_ru_test['reference'].astype(str), scores_zh_test['reference']\n",
    "    elif ref_trans == 'translation':\n",
    "        a,b,c = scores_cs_test['translation'], scores_de_test['translation'], scores_en_fi_test['translation']\n",
    "        d,e,f = scores_en_zh_test['translation'], scores_ru_test['translation'].astype(str), scores_zh_test['translation']\n",
    "        \n",
    "    ref_trans_cs = preprocessing(a,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_de = preprocessing(b,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_en_fi = preprocessing(c,'finnish', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_en_zh = preprocessing(d,'zh', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_ru = preprocessing(e,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    ref_trans_zh = preprocessing(f,'eng', pontuation = pontuation, \n",
    "                                  lemmatize=lemmatize, stemmer=stemmer, stop_words = stop_words)\n",
    "    \n",
    "    out = ref_trans_cs, ref_trans_de, ref_trans_en_fi, ref_trans_en_zh, ref_trans_ru, ref_trans_zh\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for calculating cosine similarity\n",
    "scores_cs_test['Cosine_similarity'], scores_de_test['Cosine_similarity'] = 0, 0\n",
    "scores_ru_test['Cosine_similarity'], scores_zh_test['Cosine_similarity'] = 0, 0\n",
    "scores_en_fi_test['Cosine_similarity'], scores_en_zh_test['Cosine_similarity'] = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6eedeee2584896bbb8ccec2538ca23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8732.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cb56c1b8f24a17a55a674c3209ee9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505daf803b2a4c17946113baea255cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8097.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32296edb3144c6fb0623724da87f87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3592e7a2acaa4692abaf826f2462284b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da037c189abb4ca58e2c115c6e19e1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25352.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f79f0a34ea48afb40a4d614caf438d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8732.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1d4c9c68744c70a236c1d454fbd67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce2bc3dadce43228fdd623454b177d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8097.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db11690ec904014816dbcf92e5bc71b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8521c026097b485a8339ae7e3cb8c131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bdd67cbfd54f39af290776d84c1b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25352.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All parameters set to False\n",
    "# (stopwords and punctuation will be deleted by words_count functions)\n",
    "references_cs_test, references_de_test, references_en_fi_test, references_en_zh_test, references_ru_test, references_zh_test = prep_test(\n",
    "    'referece', pontuation = False, lemmatize=False, stemmer=False, stop_words = False)\n",
    "\n",
    "translation_cs_test, translation_de_test, translation_en_fi_test, translation_en_zh_test, translation_ru_test, translation_zh_test = prep_test(\n",
    "    'translation', pontuation = False, lemmatize=False, stemmer=False, stop_words = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f926832f9948e0b7e76da3db628048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8732.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b548d07cb31d4d998b3e456ed707444f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=28404.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c0a274fb9a4be6919ce8079a907984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a732db232072459d8368f968fd0728ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=25352.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ed7e05e8c2427db86f6cbcb024a47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=22128.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create lists with pre-processed series to work with\n",
    "# All parameters of pre-processing set to True except Stemmer\n",
    "ref_list_test = [references_cs_test, references_de_test, references_ru_test, references_zh_test, references_en_zh_test]\n",
    "trans_list_test = [translation_cs_test, translation_de_test, translation_ru_test, translation_zh_test, translation_en_zh_test]\n",
    "scores_test = [scores_cs_test, scores_de_test, scores_ru_test, scores_zh_test, scores_en_zh_test]\n",
    "# Calculate cosine similarity (without lemmatizationm removing stop-words and )\n",
    "cos_s(ref_list_test, trans_list_test, scores_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in scores_test:\n",
    "    doc = doc.rename(columns={'Cosine_similarity': 'metric'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file with 'metric' column\n",
    "\n",
    "\n",
    "scores_cs_test.to_csv(\"testset/cs-en/scores.csv\", index=False)\n",
    "scores_de_test.to_csv(\"testset/de-en/scores.csv\", index=False)\n",
    "\n",
    "scores_en_zh_test.to_csv(\"testset/en-zh/scores.csv\", index=False)\n",
    "scores_ru_test.to_csv(\"testset/ru-en/scores.csv\", index=False)\n",
    "scores_zh_test.to_csv(\"testset/zh-en/scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fiinish language:\n",
    "- use multilingual BERT and finBERT to get sentence embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained multilingual BERT model \n",
    "# to get sentence embeddings\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything works ok\n",
    "text = \"Long text about stars.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)\n",
    "last_hidden_states = output[0]\n",
    "cls_embedding = last_hidden_states[0][0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001192092896"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check cosine similarity for identical lines - should be equal 1\n",
    "normalize_a = tf.nn.l2_normalize(cls_embedding,0)        \n",
    "normalize_b = tf.nn.l2_normalize(cls_embedding,0)\n",
    "cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "float(cos_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d21c8f03e8745569fdeb4453df55b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained BERT \n",
    "scores_en_fi['Cosine_similarity_base'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi1[doc]\n",
    "    text2 = translation_en_fi1[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer(text1, return_tensors='tf')\n",
    "    output1 = model(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer(text2, return_tensors='tf')\n",
    "    output2 = model(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity_base'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15062687657592824"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will pre-process finish docs, trying to increase our correlation with z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lehmähaude\n"
     ]
    }
   ],
   "source": [
    "# Attention: this library can have some isuues during installation\n",
    "# Some advices how to resolve them from offical page - https://voikko.puimula.org/python.html\n",
    "\n",
    "# Check how this library works:\n",
    "#Define a Voikko class for Finnish\n",
    "v = libvoikko.Voikko(u\"fi\")\n",
    "\n",
    "#A word that might or might not be in base form\n",
    "word = \"lehmähauteen\"\n",
    "\n",
    "#Analyze the word\n",
    "voikko_dict = v.analyze(word)\n",
    "\n",
    "#Extract the base form as\n",
    "#analyze() function returns various info for the word\n",
    "word_baseform = voikko_dict[0]['BASEFORM']\n",
    "\n",
    "#Print the base form of the word\n",
    "print(word_baseform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stopwords, lemmatize using Voikko\n",
    "def preprocess_fi(alltext):\n",
    "    processed_corpus = []\n",
    "    #stop_words = set(stopwords.words())\n",
    "    for i in tqdm(range(len(alltext))):\n",
    "        text = alltext[i]\n",
    "        # Tokenize\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        # tokenize text\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        temp = []\n",
    "        #Define a Voikko class for Finnish\n",
    "        v = libvoikko.Voikko(u\"fi\")\n",
    "\n",
    "        # Change words to lemmas\n",
    "        for word in tokens:\n",
    "            voikko_dict = v.analyze(word)\n",
    "            try:\n",
    "                t = voikko_dict[0]['BASEFORM']\n",
    "                temp.append(t)\n",
    "            except:\n",
    "                temp.append(word)\n",
    "                continue\n",
    "        tokens = temp\n",
    "        # delete stop words\n",
    "        tokens = list(filter(lambda x: x not in stop_words_fi, tokens))\n",
    "        #Convert to lowercase because Voikko returns some words that begin from upper case\n",
    "        text = text.lower()\n",
    "        text = \" \".join(tokens)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da684d24ae2438c91fada54af39b305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e38fd543394e458564c6195d5dcc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre-process finnish sentences (references and translations using preprocess_fi)\n",
    "references_en_fi_new = preprocess_fi(references_en_fi1)\n",
    "translation_en_fi_new = preprocess_fi(translation_en_fi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained multilingual BERT model \n",
    "# to get sentence embeddings for pre-processed references and translations\n",
    "\n",
    "tokenizer1 = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model1 = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edba4fef448d4f20ade9aeeb8e9d34c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained BERT \n",
    "# for pre-processed finnish text (we pre-processed it in a 1st part) \n",
    "# (cleaned andd lemmatized with Voikko)\n",
    "scores_en_fi['Cosine_similarity'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi_new[doc]\n",
    "    text2 = translation_en_fi_new[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer1(text1, return_tensors='tf')\n",
    "    output1 = model1(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer1(text2, return_tensors='tf')\n",
    "    output2 = model1(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1615293553059098"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Pearson correlation\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We increased to 0.161 from 0.150, but still a room for improvment - we will try to work with finBERT\n",
    "# BERT model that is trained and fine-tuned for finnish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finBERT from TurkuNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained finnish language BERT model - finBERT from TurkuNLP \n",
    "# to get sentence embeddings\n",
    "\n",
    "tokenizer2 = BertTokenizer.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "model2 = TFBertModel.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000238418579"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if our model works - cakculate cosine simila\n",
    "text = \"varastettujen polkupyörän ostajat ovat tavanomaisia suomalaisia, poliisin mukaan.\"\n",
    "encoded_input = tokenizer2(text, return_tensors='tf')\n",
    "output = model2(encoded_input)\n",
    "last_hidden_states = output[0]\n",
    "cls_embedding = last_hidden_states[0][0]  \n",
    "normalize_a = tf.nn.l2_normalize(cls_embedding,0)        \n",
    "normalize_b = tf.nn.l2_normalize(cls_embedding,0)\n",
    "cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "float(cos_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22932ecdca694803848f3a2dd23edf2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained finBERT \n",
    "# (without lemmatization)\n",
    "\n",
    "scores_en_fi['Cosine_similarity_finBERT_base'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi1[doc]\n",
    "    text2 = translation_en_fi1[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer2(text1, return_tensors='tf')\n",
    "    output1 = model2(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer2(text2, return_tensors='tf')\n",
    "    output2 = model2(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity_finBERT_base'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164684269163455"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print cosine similarity\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finBERT with pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained finnish language BERT model - finBERT from TurkuNLP \n",
    "# to get sentence embeddings\n",
    "\n",
    "tokenizer3 = BertTokenizer.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "model3 = TFBertModel.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa1f1dfed9640268611a35963abc3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained finBERT \n",
    "# and pre-processed finnish text - cleaned and lemmatized\n",
    "\n",
    "scores_en_fi['Cosine_similarity_finBERT'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi_new[doc]\n",
    "    text2 = translation_en_fi_new[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer3(text1, return_tensors='tf')\n",
    "    output1 = model3(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer3(text2, return_tensors='tf')\n",
    "    output2 = model3(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity_finBERT'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4842557556811352"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print cosine similarity\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare cosine similarities for all models\n",
    "index = ['Multilingual BERT without pre-process', 'Multilingual BERT with pre-process', \n",
    "           'finBERT (TurkuNLP) without pre-process', 'finBERT (TurkuNLP) with pre-process']\n",
    "data = []\n",
    "columns = ['en-fi']\n",
    "finish_corr = pd.DataFrame(data, columns=columns, index = index)\n",
    "finish_corr.iloc[0] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_base'])\n",
    "finish_corr.iloc[1] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity'])\n",
    "finish_corr.iloc[2] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT_base'])\n",
    "finish_corr.iloc[3] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en-fi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multilingual BERT without pre-process</th>\n",
       "      <td>0.150627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multilingual BERT with pre-process</th>\n",
       "      <td>0.161529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finBERT (TurkuNLP) without pre-process</th>\n",
       "      <td>0.616468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finBERT (TurkuNLP) with pre-process</th>\n",
       "      <td>0.484256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           en-fi\n",
       "Multilingual BERT without pre-process   0.150627\n",
       "Multilingual BERT with pre-process      0.161529\n",
       "finBERT (TurkuNLP) without pre-process  0.616468\n",
       "finBERT (TurkuNLP) with pre-process     0.484256"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate metric for test set en-fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e35d430cf149dea27250411c745d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=8097.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained finBERT \n",
    "# (without lemmatization)\n",
    "\n",
    "scores_en_fi_test['Cosine_similarity'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi_test))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi_test[doc]\n",
    "    text2 = translation_en_fi_test[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer2(text1, return_tensors='tf')\n",
    "    output1 = model2(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer2(text2, return_tensors='tf')\n",
    "    output2 = model2(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi_test['Cosine_similarity'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_en_fi_test.rename(columns={'Cosine_similarity': 'metric'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One local resident who did not wish to be name...</td>\n",
       "      <td>Eräs paikallinen asukas, joka ei halunnut nime...</td>\n",
       "      <td>Toisen nimettömänä pysyttelevän asukkaan mukaa...</td>\n",
       "      <td>0.754227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still, she clings to a chant she's committed t...</td>\n",
       "      <td>Silti hän takertuu chant hän on sitoutunut mui...</td>\n",
       "      <td>Silti hän luottaa edelleen iskulauseeseen, jon...</td>\n",
       "      <td>0.735724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't want to be asked, 'What were you doing...</td>\n",
       "      <td>En halua, että minulta kysytään: \"Mitä te teit...</td>\n",
       "      <td>En halua, että kenenkään tarvitsee kysyä minul...</td>\n",
       "      <td>0.868746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I wouldn't say it was a lie – that's a pretty...</td>\n",
       "      <td>\"En sanoisi, että se oli valhe - se on aika ro...</td>\n",
       "      <td>En sanoisi, että se oli valhe, se on aika kova...</td>\n",
       "      <td>0.855505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kari Kola took part in the opening ceremony of...</td>\n",
       "      <td>Kari Kola osallistui valon vuoden avajaisiin v...</td>\n",
       "      <td>Kari Kola oli mukana Valon teemavuoden avajais...</td>\n",
       "      <td>0.975093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8092</th>\n",
       "      <td>Dubai's civil defence authorities said firefig...</td>\n",
       "      <td>Dubain siviilipuolustusviranomaisten mukaan pa...</td>\n",
       "      <td>Dubain pelastusviranomaisten mukaan sammutusjo...</td>\n",
       "      <td>0.937237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8093</th>\n",
       "      <td>But most contemporary animals that have counte...</td>\n",
       "      <td>Mutta useimmat nykyajan eläimet, jotka ovat va...</td>\n",
       "      <td>Nykyisistä eläimistä esimerkiksi peuroilla, se...</td>\n",
       "      <td>0.854175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8094</th>\n",
       "      <td>Tommi, his spouse Riina and their two small ch...</td>\n",
       "      <td>Tommi, hänen puolisonsa Riina ja heidän kaksi ...</td>\n",
       "      <td>Tommi, hänen avopuolisonsa Riina ja pariskunna...</td>\n",
       "      <td>0.973322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>Tenacious outdoor swim school students in Imat...</td>\n",
       "      <td>Sitkeitä ulko-uintikoululaisia Imatralla ei hu...</td>\n",
       "      <td>Imatran sinnikkäitä rantauimakoululaisia ei he...</td>\n",
       "      <td>0.914061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>With his assignment in the castle over, Rhodes...</td>\n",
       "      <td>Kun hänen tehtävänsä linnassa ohi, Rhodes on m...</td>\n",
       "      <td>Nyt Rhodes hakee uusia kirjoituskokemuksia.</td>\n",
       "      <td>0.838537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8097 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     One local resident who did not wish to be name...   \n",
       "1     Still, she clings to a chant she's committed t...   \n",
       "2     I don't want to be asked, 'What were you doing...   \n",
       "3     \"I wouldn't say it was a lie – that's a pretty...   \n",
       "4     Kari Kola took part in the opening ceremony of...   \n",
       "...                                                 ...   \n",
       "8092  Dubai's civil defence authorities said firefig...   \n",
       "8093  But most contemporary animals that have counte...   \n",
       "8094  Tommi, his spouse Riina and their two small ch...   \n",
       "8095  Tenacious outdoor swim school students in Imat...   \n",
       "8096  With his assignment in the castle over, Rhodes...   \n",
       "\n",
       "                                              reference  \\\n",
       "0     Eräs paikallinen asukas, joka ei halunnut nime...   \n",
       "1     Silti hän takertuu chant hän on sitoutunut mui...   \n",
       "2     En halua, että minulta kysytään: \"Mitä te teit...   \n",
       "3     \"En sanoisi, että se oli valhe - se on aika ro...   \n",
       "4     Kari Kola osallistui valon vuoden avajaisiin v...   \n",
       "...                                                 ...   \n",
       "8092  Dubain siviilipuolustusviranomaisten mukaan pa...   \n",
       "8093  Mutta useimmat nykyajan eläimet, jotka ovat va...   \n",
       "8094  Tommi, hänen puolisonsa Riina ja heidän kaksi ...   \n",
       "8095  Sitkeitä ulko-uintikoululaisia Imatralla ei hu...   \n",
       "8096  Kun hänen tehtävänsä linnassa ohi, Rhodes on m...   \n",
       "\n",
       "                                            translation    metric  \n",
       "0     Toisen nimettömänä pysyttelevän asukkaan mukaa...  0.754227  \n",
       "1     Silti hän luottaa edelleen iskulauseeseen, jon...  0.735724  \n",
       "2     En halua, että kenenkään tarvitsee kysyä minul...  0.868746  \n",
       "3     En sanoisi, että se oli valhe, se on aika kova...  0.855505  \n",
       "4     Kari Kola oli mukana Valon teemavuoden avajais...  0.975093  \n",
       "...                                                 ...       ...  \n",
       "8092  Dubain pelastusviranomaisten mukaan sammutusjo...  0.937237  \n",
       "8093  Nykyisistä eläimistä esimerkiksi peuroilla, se...  0.854175  \n",
       "8094  Tommi, hänen avopuolisonsa Riina ja pariskunna...  0.973322  \n",
       "8095  Imatran sinnikkäitä rantauimakoululaisia ei he...  0.914061  \n",
       "8096        Nyt Rhodes hakee uusia kirjoituskokemuksia.  0.838537  \n",
       "\n",
       "[8097 rows x 4 columns]"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_en_fi_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_en_fi_test.to_csv(\"testset/en-fi/scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
