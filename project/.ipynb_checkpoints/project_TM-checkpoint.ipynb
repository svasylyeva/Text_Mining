{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Import libraries\n",
    "import nltk.translate.chrf_score as chrf\n",
    "from rouge import Rouge\n",
    "import nltk\n",
    "import nltk.translate.gleu_score as gleu\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "try:\n",
    "  nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "  nltk.download('punkt')\n",
    "import nltk.translate.meteor_score as meteor\n",
    "import nltk.translate.nist_score as nist\n",
    "import nltk.translate.bleu_score as bleu\n",
    "\n",
    "#import spacy\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#import itertools\n",
    "\n",
    "import codecs\n",
    "import jieba\n",
    "\n",
    "#Import nltk Snowball stemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "from stop_words import get_stop_words\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cs = pd.read_csv(\"corpus/cs-en/scores.csv\")\n",
    "scores_de = pd.read_csv(\"corpus/de-en/scores.csv\")\n",
    "scores_en_fi = pd.read_csv(\"corpus/en-fi/scores.csv\")\n",
    "scores_en_zh = pd.read_csv(\"corpus/en-zh/scores.csv\")\n",
    "scores_ru = pd.read_csv(\"corpus/ru-en/scores.csv\")\n",
    "scores_zh = pd.read_csv(\"corpus/zh-en/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work with contractions using pycontractes lib that chooses a proper form\n",
    "# instead ambiguous \"you'd\" -> \"you had / you would\"\n",
    "\n",
    "from pycontractions import Contractions\n",
    "\n",
    "# Download 'GoogleNews-vectors-negative300.bin' file to a folder with this jupiter notebook\n",
    "# if needed (size is more 3 Gb)\n",
    "# archive on - https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
    "cont = Contractions('GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "# prevents loading on first expand_texts call\n",
    "# usually takes time\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = scores_de.translation\n",
    "a[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series(list(cont.expand_texts(a, precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it is now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how contracion expanding worked\n",
    "b[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As contraction extractions work really slow\n",
    "# they were done outside preprocessing function\n",
    "references_cs = pd.Series(list(cont.expand_texts(scores_cs['reference'], precise=True)))\n",
    "references_de = pd.Series(list(cont.expand_texts(scores_de['reference'], precise=True)))\n",
    "references_ru = pd.Series(list(cont.expand_texts(scores_ru['reference'], precise=True)))\n",
    "references_zh = pd.Series(list(cont.expand_texts(scores_zh['reference'], precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for translations\n",
    "translation_cs = pd.Series(list(cont.expand_texts(scores_cs['translation'], precise=True)))\n",
    "translation_de = pd.Series(list(cont.expand_texts(scores_de['translation'], precise=True)))\n",
    "translation_ru = pd.Series(list(cont.expand_texts(scores_ru['translation'], precise=True)))\n",
    "translation_zh = pd.Series(list(cont.expand_texts(scores_zh['translation'], precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.    ---->  \n",
      " it is now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.\n"
     ]
    }
   ],
   "source": [
    "# Check how expanding contractions worked\n",
    "print(scores_de['translation'][6], '   ---->  \\n',translation_de[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# release references and 'garbage collect' to free memory\n",
    "import gc\n",
    "del cont\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(series, pontuation = False, zh = False):\n",
    "    processed_corpus = []\n",
    "    #stop_words = set(stopwords.words())\n",
    "    for i in tqdm(range(len(series))):\n",
    "        text = series[i]\n",
    "        \n",
    "        #remove tags\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        #Remove punctuations\n",
    "        if pontuation==True:\n",
    "            text = re.sub(r'[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，？、~@#￥%……&*（）:：；《）《》“”()»〔〕-]+', ' ', text)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Convert to list from string\n",
    "        \n",
    "        # For en-zh language pair use jieba for words cut\n",
    "        if zh == True:\n",
    "            text = jieba.cut_for_search(text)\n",
    "        else:\n",
    "            text = text.split()\n",
    "\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        #text = [lem.lemmatize(word) for word in text if not word in stop_words] \n",
    "        text = \" \".join(text)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf6d69f5a694cd4b30a9562db7ca679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d1e027940f45dd80f5953ee3ef90cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7a5b158d8c48ae8e5d6e0247d9e4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f415211ee6a94f95a1ebc9b89077cddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\murmu\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.682 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2381e498e5e5498a890ddc368ab837be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32193360ed5a4124adb578e97eede883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "references_cs = preprocessing(references_cs)\n",
    "references_de = preprocessing(references_de)\n",
    "references_en_fi = preprocessing(scores_en_fi['reference'])\n",
    "references_en_zh = preprocessing(scores_en_zh['reference'], zh = True)\n",
    "references_ru = preprocessing(references_ru)\n",
    "references_zh = preprocessing(references_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ecbabbdeed4bb3b357b39d586ed7e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1406c7dff0c456dafc8a47918dbfd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50059d61a5c64bbbbb710b78bb8939ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e4c1adb2f945f2992a4fc335c0a527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d27afbc5f8f4c7796e3624bbbb2c89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de174b8e8b645089608a3dd78ff5db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translation_cs = preprocessing(translation_cs)\n",
    "translation_de = preprocessing(translation_de)\n",
    "translation_en_fi = preprocessing(scores_en_fi['translation'])\n",
    "translation_en_zh = preprocessing(scores_en_zh['translation'], zh = True)\n",
    "translation_ru = preprocessing(translation_ru)\n",
    "translation_zh = preprocessing(translation_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS from your file text_mining1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrf_metric(translation, references):\n",
    "    chrf_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = chrf.sentence_chrf([translation[i]], references[i])\n",
    "        chrf_metric.append(row)\n",
    "    return chrf_metric\n",
    "\n",
    "chf_cs = chrf_metric(translation_cs, references_cs)\n",
    "scores_cs['chf'] = chf_cs\n",
    "chf_de = chrf_metric(translation_de, references_de)\n",
    "scores_de['chf'] = chf_de\n",
    "chf_en_fi = chrf_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['chf'] = chf_en_fi\n",
    "chf_en_zh = chrf_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['chf'] = chf_en_zh\n",
    "chf_ru = chrf_metric(translation_ru, references_ru)\n",
    "scores_ru['chf'] = chf_ru\n",
    "chf_zh = chrf_metric(translation_zh, references_zh)\n",
    "scores_zh['chf'] = chf_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gleu_metric(translation, references):\n",
    "    gleu_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = gleu.sentence_gleu([str(references[i]).split()], str(translation[i]).split(), min_len=1, max_len=2)\n",
    "        gleu_metric.append(row)\n",
    "    return gleu_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gleu_cs = gleu_metric(translation_cs, references_cs)\n",
    "scores_cs['gleu'] = gleu_cs\n",
    "\n",
    "gleu_de = gleu_metric(translation_de, references_de)\n",
    "scores_de['gleu'] = gleu_de\n",
    "\n",
    "gleu_en_fi = gleu_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['gleu'] = gleu_en_fi\n",
    "\n",
    "gleu_en_zh = gleu_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['gleu'] = gleu_en_zh\n",
    "\n",
    "gleu_ru = gleu_metric(translation_ru, references_ru)\n",
    "scores_ru['gleu'] = gleu_ru\n",
    "\n",
    "gleu_zh = gleu_metric(translation_zh, references_zh)\n",
    "scores_zh['gleu'] = gleu_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteor_metric(translation, references):\n",
    "    meteor_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (meteor.meteor_score([translation[i]], references[i]))\n",
    "        meteor_metric.append(row)\n",
    "    return meteor_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_cs = meteor_metric(translation_cs, references_cs)\n",
    "scores_cs['meteor'] = meteor_cs\n",
    "\n",
    "meteor_de = meteor_metric(translation_de, references_de)\n",
    "scores_de['meteor'] = meteor_de\n",
    "\n",
    "meteor_en_fi = meteor_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['meteor'] = meteor_en_fi\n",
    "\n",
    "meteor_en_zh = meteor_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['meteor'] = meteor_en_zh\n",
    "\n",
    "meteor_ru = meteor_metric(translation_ru, references_ru)\n",
    "scores_ru['meteor'] = meteor_ru\n",
    "\n",
    "meteor_zh = meteor_metric(translation_zh, references_zh)\n",
    "scores_zh['meteor'] = meteor_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_metric(translation, references):\n",
    "    bleu_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (bleu.sentence_bleu([translation[i]], references[i]))\n",
    "        bleu_metric.append(row)\n",
    "    return bleu_metric\n",
    "\n",
    "bleu_cs = bleu_metric(translation_cs, references_cs)\n",
    "scores_cs['bleu'] = bleu_cs\n",
    "\n",
    "bleu_de = bleu_metric(translation_de, references_de)\n",
    "scores_de['bleu'] = bleu_de\n",
    "\n",
    "bleu_en_fi = bleu_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['bleu'] = bleu_en_fi\n",
    "\n",
    "bleu_en_zh = bleu_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['bleu'] = bleu_en_zh\n",
    "\n",
    "bleu_ru = bleu_metric(translation_ru, references_ru)\n",
    "scores_ru['bleu'] = bleu_ru\n",
    "\n",
    "bleu_zh = bleu_metric(translation_zh, references_zh)\n",
    "scores_zh['bleu'] = bleu_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nist_metric(translation, references):\n",
    "    nist_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (nist.sentence_nist([translation[i]], references[i],n=1))\n",
    "        nist_metric.append(row)\n",
    "    return nist_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_cs = nist_metric(translation_cs, references_cs)\n",
    "scores_cs['nist'] = nist_cs\n",
    "\n",
    "nist_de = nist_metric(translation_de, references_de)\n",
    "scores_de['nist'] = nist_de\n",
    "\n",
    "nist_en_fi = nist_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['nist'] = nist_en_fi\n",
    "\n",
    "nist_en_zh = nist_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['nist'] = nist_en_zh\n",
    "\n",
    "nist_ru = nist_metric(translation_ru, references_ru)\n",
    "scores_ru['nist'] = nist_ru\n",
    "\n",
    "nist_zh = nist_metric(translation_zh, references_zh)\n",
    "scores_zh['nist'] = nist_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(scores):\n",
    "    chf = scores['z-score'].corr(scores['chf'])\n",
    "    gleu = scores['z-score'].corr(scores['gleu'])\n",
    "    meteor = scores['z-score'].corr(scores['meteor'])\n",
    "    bleu = scores['z-score'].corr(scores['bleu'])\n",
    "    nist = scores['z-score'].corr(scores['nist'])\n",
    "    #ribes = scores['z-score'].corr(scores['ribes'])\n",
    "    corr = [chf, gleu, meteor, bleu, nist]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cs = corr(scores_cs)\n",
    "corr_de = corr(scores_de)\n",
    "corr_en_fi = corr(scores_en_fi)\n",
    "corr_en_zh = corr(scores_en_zh)\n",
    "corr_ru = corr(scores_ru)\n",
    "corr_zh = corr(scores_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['chf', 'gleu', 'meteor', 'bleu', 'nist']\n",
    "data = []\n",
    "index = ['scores_cs', 'scores_de', 'scores_en_fi', 'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "correlation.iloc[0] = corr_cs\n",
    "correlation.iloc[1] = corr_de\n",
    "correlation.iloc[2] = corr_en_fi\n",
    "correlation.iloc[3] = corr_en_zh\n",
    "correlation.iloc[4] = corr_ru\n",
    "correlation.iloc[5] = corr_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "      <th>nist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.462242</td>\n",
       "      <td>0.427902</td>\n",
       "      <td>0.440021</td>\n",
       "      <td>0.46878</td>\n",
       "      <td>0.334652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.341181</td>\n",
       "      <td>0.310139</td>\n",
       "      <td>0.308167</td>\n",
       "      <td>0.346757</td>\n",
       "      <td>0.227363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.611567</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.491475</td>\n",
       "      <td>0.619928</td>\n",
       "      <td>0.423513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.468428</td>\n",
       "      <td>0.432876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361416</td>\n",
       "      <td>0.333537</td>\n",
       "      <td>0.336712</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.26207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.341225</td>\n",
       "      <td>0.317931</td>\n",
       "      <td>0.326407</td>\n",
       "      <td>0.351904</td>\n",
       "      <td>0.244659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chf      gleu    meteor      bleu      nist\n",
       "scores_cs     0.462242  0.427902  0.440021   0.46878  0.334652\n",
       "scores_de     0.341181  0.310139  0.308167  0.346757  0.227363\n",
       "scores_en_fi  0.611567  0.494636  0.491475  0.619928  0.423513\n",
       "scores_en_zh  0.423398  0.449157  0.453092  0.468428  0.432876\n",
       "scores_ru     0.361416  0.333537  0.336712  0.367581   0.26207\n",
       "scores_zh     0.341225  0.317931  0.326407  0.351904  0.244659"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline correlation\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cosine similarities for sentences using word embeddings\n",
    " - we use pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english stopwords\n",
    "english_stop_words = set(stopwords.words('english')).union(STOP_WORDS)\n",
    "\n",
    "# chinese stopwords\n",
    "#stopwords_zh = codecs.open('stopwords-zh.txt', 'r', 'utf-8').read().split(',')\n",
    "stopwords_zh = set(line.strip() for line in open('stopwords-zh.txt', encoding='utf8'))\n",
    "\n",
    "# finnish stopwords\n",
    "stop_words_fi = get_stop_words('finnish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stopwords, lemmatize if needed\n",
    "\n",
    "def words_count(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "   \n",
    "    # delete stop words\n",
    "    tokens = list(filter(lambda x: x not in english_stop_words, tokens))\n",
    "    \n",
    "    # lemmatize the words WordNetLemmatizer from nlkt\n",
    "    # this made Pearson correlation lower - so was commented\n",
    "    \n",
    "    # tokens = list(map(lambda x: nltk.WordNetLemmatizer().lemmatize(x), tokens))\n",
    "    \n",
    "    # With spacy lemmatizer (worked better than nltk)\n",
    "    # it is commented because it made correlation lower\n",
    "    # tokens = list(map(lambda x: [token.lemma_ for token in nlp(x)], tokens))\n",
    "    # tokens = list(itertools.chain(*tokens))\n",
    "    \n",
    "    return list(Counter(tokens).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stopwords, lemmatize if needed\n",
    "\n",
    "def words_count_zh(text):\n",
    "#     # Tokenize\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # delete stop words\n",
    "    tokens = list(filter(lambda x: x not in stopwords_zh, tokens))\n",
    "    return list(Counter(tokens).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained GloVe (Global Vectors for Word Representation) word vectors.\n",
    "# For cs, de, ru, zh that translated to english\n",
    "# 6B tokens, 400K vocab, (300d version).\n",
    "# Download file from https://www.kaggle.com/thanakomsn/glove6b300dtxt\n",
    "# to a folder with this jupiter notebook (size 1Gb)\n",
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "    return word_to_vec_map\n",
    "# Download glove.6B.300d.txt to a folder with this jupiter notebook\n",
    "word_to_vec_map = read_glove_vecs('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese word vector\n",
    "# Download word vectors file from https://www.kaggle.com/kerneler/starter-sgns-merge-word-18e5b7b5-9/execution?select=sgns.merge.word\n",
    "# file to a folder with this jupiter notebook (size 3.5Gb)\n",
    "word_to_vec_zh = read_glove_vecs('sgns.merge.word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could not find glove nodel for finnish,\n",
    "# so will work with finnish language separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column for calculating cosine similarity\n",
    "scores_cs['Cosine_similarity'], scores_de['Cosine_similarity'] = 0, 0\n",
    "scores_ru['Cosine_similarity'], scores_zh['Cosine_similarity'] = 0, 0\n",
    "scores_en_fi['Cosine_similarity'], scores_en_zh['Cosine_similarity'] = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists with languages to work with\n",
    "ref_list = [references_cs, references_de, references_ru, references_zh, references_en_zh]\n",
    "trans_list = [translation_cs, translation_de, translation_ru, translation_zh, translation_en_zh]\n",
    "scores = [scores_cs, scores_de, scores_ru, scores_zh, scores_en_zh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5300a45c342a4d108c6d8b7490f92d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920e8690dff44302b6b7b13d28d62003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4119867a4f9343b3bda83b24f0781d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c14ad6081d740289bd1a9503e785255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f330e99c75479ca2140477615cf0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check cosine similarity between two sentences (reference and translation)\n",
    "# Use different pre-trained word embeddings:\n",
    "# GloVe - for cs, de, ru, zh that translated to english\n",
    "# 'sgns.merge.word' - for en-zh pair\n",
    "\n",
    "for doc in range(len(scores)):\n",
    "    ref_embeddings = np.zeros((len(scores[doc]),300))\n",
    "    tr_embeddings = np.zeros((len(scores[doc]),300))\n",
    "    \n",
    "    norms_doc_embeddings_tr = np.zeros((len(trans_list[doc]),1))\n",
    "    norms_doc_embeddings_ref = np.zeros((len(ref_list[doc]),1))\n",
    "    \n",
    "    Cosine_similarity = []\n",
    "    \n",
    "    for i in tqdm(range(len(trans_list[doc]))):\n",
    "        if doc == 4:\n",
    "            words_freq = words_count_zh(trans_list[doc][i])\n",
    "            doc_embeddings = np.zeros(word_to_vec_zh[\"a\"].shape)\n",
    "        \n",
    "        else:\n",
    "            words_freq = words_count(trans_list[doc][i])\n",
    "            doc_embeddings = np.zeros(word_to_vec_map[\"a\"].shape)\n",
    "        num_words = 0\n",
    "        for word_freq in words_freq:\n",
    "            word = word_freq[0]\n",
    "            freq = word_freq[1]\n",
    "            try:\n",
    "                #adding word embeddings for each word in the document\n",
    "                if doc == 4:\n",
    "                    doc_embeddings += (word_to_vec_zh[word] * freq)\n",
    "                else:\n",
    "                    doc_embeddings += (word_to_vec_map[word] * freq)\n",
    "                num_words += freq\n",
    "            except:\n",
    "                continue\n",
    "        try:\n",
    "            # doing average\n",
    "            doc_embeddings /= num_words\n",
    "        except:\n",
    "            print(\"divide by zero encountered for article at index \"+str(i))\n",
    "            continue\n",
    "        norms_doc_embeddings_tr[i,:] = np.sqrt(np.dot(doc_embeddings,doc_embeddings))\n",
    "        tr_embeddings[i,:] = doc_embeddings\n",
    "        \n",
    "        \n",
    "        if doc == 4:\n",
    "            words_freq = words_count_zh(ref_list[doc][i])\n",
    "            doc_embeddings = np.zeros(word_to_vec_zh[\"a\"].shape)\n",
    "        else:\n",
    "            words_freq = words_count(ref_list[doc][i])\n",
    "            doc_embeddings = np.zeros(word_to_vec_map[\"a\"].shape)\n",
    "        num_words = 0\n",
    "        for word_freq in words_freq:\n",
    "            word = word_freq[0]\n",
    "            freq = word_freq[1]\n",
    "            try:\n",
    "                #adding word embeddings for each word in the document\n",
    "                if doc == 4:\n",
    "                    doc_embeddings += (word_to_vec_zh[word] * freq)\n",
    "                \n",
    "                else:\n",
    "                    doc_embeddings += (word_to_vec_map[word] * freq)\n",
    "                num_words += freq\n",
    "            except:\n",
    "                continue\n",
    "        try:\n",
    "            # doing average\n",
    "            doc_embeddings /= num_words\n",
    "        except:\n",
    "            print(\"divide by zero encountered for article at index \"+str(i))\n",
    "            continue\n",
    "        norms_doc_embeddings_ref[i,:] = np.sqrt(np.dot(doc_embeddings,doc_embeddings))\n",
    "        ref_embeddings[i,:] = doc_embeddings\n",
    "    \n",
    "        # Calculate cosine similarity using dot product of two vectors\n",
    "        # and norms of vectors\n",
    "        \n",
    "        #  The cosine similarity depends on the angle between  vectors .\n",
    "        #  If  vectors  are very similar, their cosine similarity will be close to 1\n",
    "        norm_prods = norms_doc_embeddings_ref[i] * norms_doc_embeddings_tr[i]\n",
    "        dot_prod = np.dot(ref_embeddings[i], tr_embeddings[i].reshape(300,1))\n",
    "        cos_similarity = dot_prod / norm_prods\n",
    "        \n",
    "        Cosine_similarity.append(float(cos_similarity))\n",
    "    \n",
    "    scores[doc]['Cosine_similarity'] = pd.Series(Cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_new(scores):\n",
    "    chf = scores['z-score'].corr(scores['chf'])\n",
    "    gleu = scores['z-score'].corr(scores['gleu'])\n",
    "    meteor = scores['z-score'].corr(scores['meteor'])\n",
    "    bleu = scores['z-score'].corr(scores['bleu'])\n",
    "    nist = scores['z-score'].corr(scores['nist'])\n",
    "    cos = scores['z-score'].corr(scores['Cosine_similarity'])\n",
    "    corr = [chf, gleu, meteor, bleu, nist, cos]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cs_new = corr_new(scores_cs)\n",
    "corr_de_new = corr_new(scores_de)\n",
    "corr_ru_new = corr_new(scores_ru)\n",
    "corr_zh_new = corr_new(scores_zh)\n",
    "\n",
    "corr_en_zh_new = corr_new(scores_en_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['chf', 'gleu', 'meteor', 'bleu', 'nist', 'Cos_sim']\n",
    "data = []\n",
    "index = ['scores_cs', 'scores_de',  'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "correlation.iloc[0] = corr_cs_new\n",
    "correlation.iloc[1] = corr_de_new\n",
    "correlation.iloc[2] = corr_en_zh_new\n",
    "\n",
    "correlation.iloc[3] = corr_ru_new\n",
    "correlation.iloc[4] = corr_zh_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "      <th>nist</th>\n",
       "      <th>Cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.462242</td>\n",
       "      <td>0.427902</td>\n",
       "      <td>0.440021</td>\n",
       "      <td>0.46878</td>\n",
       "      <td>0.334652</td>\n",
       "      <td>0.368188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.341181</td>\n",
       "      <td>0.310139</td>\n",
       "      <td>0.308167</td>\n",
       "      <td>0.346757</td>\n",
       "      <td>0.227363</td>\n",
       "      <td>0.290548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.468428</td>\n",
       "      <td>0.432876</td>\n",
       "      <td>0.360268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361416</td>\n",
       "      <td>0.333537</td>\n",
       "      <td>0.336712</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.26207</td>\n",
       "      <td>0.304984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.341225</td>\n",
       "      <td>0.317931</td>\n",
       "      <td>0.326407</td>\n",
       "      <td>0.351904</td>\n",
       "      <td>0.244659</td>\n",
       "      <td>0.27196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chf      gleu    meteor      bleu      nist   Cos_sim\n",
       "scores_cs     0.462242  0.427902  0.440021   0.46878  0.334652  0.368188\n",
       "scores_de     0.341181  0.310139  0.308167  0.346757  0.227363  0.290548\n",
       "scores_en_zh  0.423398  0.449157  0.453092  0.468428  0.432876  0.360268\n",
       "scores_ru     0.361416  0.333537  0.336712  0.367581   0.26207  0.304984\n",
       "scores_zh     0.341225  0.317931  0.326407  0.351904  0.244659   0.27196"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate correlation between z-score and cosine_similarity columns\n",
    "# for all language pairs except finnish\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fiinish language:\n",
    "- use multilingual BERT and finBERT to get sentence embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained multilingual BERT model \n",
    "# to get sentence embeddings\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if everything works ok\n",
    "text = \"Long text about stars.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)\n",
    "last_hidden_states = output[0]\n",
    "cls_embedding = last_hidden_states[0][0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001192092896"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check cosine similarity for identical lines - should be equal 1\n",
    "normalize_a = tf.nn.l2_normalize(cls_embedding,0)        \n",
    "normalize_b = tf.nn.l2_normalize(cls_embedding,0)\n",
    "cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "float(cos_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a3fe30e0ee43489a213f5693ee4760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained BERT \n",
    "scores_en_fi['Cosine_similarity_base'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi[doc]\n",
    "    text2 = translation_en_fi[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer(text1, return_tensors='tf')\n",
    "    output1 = model(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer(text2, return_tensors='tf')\n",
    "    output2 = model(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity_base'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15062687657592824"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print cosine similarity\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will pre-process finish docs, trying to increase our correlation with z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lehmähaude\n"
     ]
    }
   ],
   "source": [
    "# Attention: this library can have some isuues during installation\n",
    "# Some advices how to resolve them from offical page - https://voikko.puimula.org/python.html\n",
    "\n",
    "#Import the Voikko to work with finnish lemmas\n",
    "import libvoikko\n",
    "\n",
    "# Check how this library works:\n",
    "\n",
    "#Define a Voikko class for Finnish\n",
    "v = libvoikko.Voikko(u\"fi\")\n",
    "\n",
    "#A word that might or might not be in base form\n",
    "word = \"lehmähauteen\"\n",
    "\n",
    "#Analyze the word\n",
    "voikko_dict = v.analyze(word)\n",
    "\n",
    "#Extract the base form as\n",
    "#analyze() function returns various info for the word\n",
    "word_baseform = voikko_dict[0]['BASEFORM']\n",
    "\n",
    "#Print the base form of the word\n",
    "print(word_baseform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete stopwords, lemmatize using Voikko\n",
    "def preprocess_fi(alltext):\n",
    "    processed_corpus = []\n",
    "    #stop_words = set(stopwords.words())\n",
    "    for i in tqdm(range(len(alltext))):\n",
    "        text = alltext[i]\n",
    "        # Tokenize\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        # tokenize text\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        temp = []\n",
    "        #Define a Voikko class for Finnish\n",
    "        v = libvoikko.Voikko(u\"fi\")\n",
    "\n",
    "        # Change words to lemmas\n",
    "        for word in tokens:\n",
    "            voikko_dict = v.analyze(word)\n",
    "            try:\n",
    "                t = voikko_dict[0]['BASEFORM']\n",
    "                temp.append(t)\n",
    "            except:\n",
    "                temp.append(word)\n",
    "                continue\n",
    "        tokens = temp\n",
    "        # delete stop words\n",
    "        tokens = list(filter(lambda x: x not in stop_words_fi, tokens))\n",
    "        #Convert to lowercase because Voikko returns some words that begin from upper case\n",
    "        text = text.lower()\n",
    "        text = \" \".join(tokens)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd267fca2084559b9a467abe3456d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7528dd42fba4cd0bdcb5c098de8e1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre-process finnish sentences (references and translations using preprocess_fi)\n",
    "references_en_fi_new = preprocess_fi(references_en_fi)\n",
    "translation_en_fi_new = preprocess_fi(translation_en_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained multilingual BERT model \n",
    "# to get sentence embeddings for pre-processed references and translations\n",
    "\n",
    "tokenizer1 = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model1 = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe207ea7a044020b628e034153177c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained BERT \n",
    "# for pre-processed finnish text (cleaned andd lemmatized with Voikko)\n",
    "scores_en_fi['Cosine_similarity'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi_new[doc]\n",
    "    text2 = translation_en_fi_new[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer1(text1, return_tensors='tf')\n",
    "    output1 = model1(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer1(text2, return_tensors='tf')\n",
    "    output2 = model1(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['chf', 'gleu', 'meteor', 'bleu', 'nist', 'Cos_sim']\n",
    "data = []\n",
    "index = ['scores_cs', 'scores_de', 'scores_en_fi', 'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "# Recalculate only en-fi score\n",
    "corr_en_fi_new = corr_new(scores_en_fi)\n",
    "\n",
    "correlation.iloc[0] = corr_cs_new\n",
    "correlation.iloc[1] = corr_de_new\n",
    "\n",
    "correlation.iloc[2] = corr_en_fi_new\n",
    "correlation.iloc[3] = corr_en_zh_new\n",
    "\n",
    "correlation.iloc[4] = corr_ru_new\n",
    "correlation.iloc[5] = corr_zh_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "      <th>nist</th>\n",
       "      <th>Cos_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.462242</td>\n",
       "      <td>0.427902</td>\n",
       "      <td>0.440021</td>\n",
       "      <td>0.46878</td>\n",
       "      <td>0.334652</td>\n",
       "      <td>0.368188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.341181</td>\n",
       "      <td>0.310139</td>\n",
       "      <td>0.308167</td>\n",
       "      <td>0.346757</td>\n",
       "      <td>0.227363</td>\n",
       "      <td>0.290548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.611567</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.491475</td>\n",
       "      <td>0.619928</td>\n",
       "      <td>0.423513</td>\n",
       "      <td>0.161529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.423398</td>\n",
       "      <td>0.449157</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.468428</td>\n",
       "      <td>0.432876</td>\n",
       "      <td>0.360268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361416</td>\n",
       "      <td>0.333537</td>\n",
       "      <td>0.336712</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.26207</td>\n",
       "      <td>0.304984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.341225</td>\n",
       "      <td>0.317931</td>\n",
       "      <td>0.326407</td>\n",
       "      <td>0.351904</td>\n",
       "      <td>0.244659</td>\n",
       "      <td>0.27196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chf      gleu    meteor      bleu      nist   Cos_sim\n",
       "scores_cs     0.462242  0.427902  0.440021   0.46878  0.334652  0.368188\n",
       "scores_de     0.341181  0.310139  0.308167  0.346757  0.227363  0.290548\n",
       "scores_en_fi  0.611567  0.494636  0.491475  0.619928  0.423513  0.161529\n",
       "scores_en_zh  0.423398  0.449157  0.453092  0.468428  0.432876  0.360268\n",
       "scores_ru     0.361416  0.333537  0.336712  0.367581   0.26207  0.304984\n",
       "scores_zh     0.341225  0.317931  0.326407  0.351904  0.244659   0.27196"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check our Pearson correlation coefficients\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We increased to 0.161 from 0.150, but still a room for improvment - we will try to work with finBERT\n",
    "# BERT model that is trained and fine-tuned for finnish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finBERT from TurkuNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained finnish language BERT model - finBERT from TurkuNLP \n",
    "# to get sentence embeddings\n",
    "\n",
    "tokenizer2 = BertTokenizer.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "model2 = TFBertModel.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000238418579"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if our model works - cakculate cosine simila\n",
    "text = \"varastettujen polkupyörän ostajat ovat tavanomaisia suomalaisia, poliisin mukaan.\"\n",
    "encoded_input = tokenizer2(text, return_tensors='tf')\n",
    "output = model2(encoded_input)\n",
    "last_hidden_states = output[0]\n",
    "cls_embedding = last_hidden_states[0][0]  \n",
    "normalize_a = tf.nn.l2_normalize(cls_embedding,0)        \n",
    "normalize_b = tf.nn.l2_normalize(cls_embedding,0)\n",
    "cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "float(cos_similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c6d9793787475b8a08cdf1acefd4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained finBERT \n",
    "# (without lemmatization)\n",
    "\n",
    "scores_en_fi['Cosine_similarity_finBERT_base'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi[doc]\n",
    "    text2 = translation_en_fi[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer2(text1, return_tensors='tf')\n",
    "    output1 = model2(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer2(text2, return_tensors='tf')\n",
    "    output2 = model2(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity_finBERT_base'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164684269163455"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print cosine similarity\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1 were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at TurkuNLP/bert-base-finnish-cased-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Download pre-trained finnish language BERT model - finBERT from TurkuNLP \n",
    "# to get sentence embeddings\n",
    "\n",
    "tokenizer3 = BertTokenizer.from_pretrained('TurkuNLP/bert-base-finnish-cased-v1')\n",
    "model3 = TFBertModel.from_pretrained(\"TurkuNLP/bert-base-finnish-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a8da56af8540f580a9d814b3516fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Attention: this cell takes more than hour to calculate cosine similaritites\n",
    "\n",
    "# Compare the embeddings of sentences that we receive with  pretrained finBERT \n",
    "# and pre-processed finnish text - cleaned and lemmatized\n",
    "\n",
    "scores_en_fi['Cosine_similarity_finBERT'] = 0\n",
    "Cosine = []\n",
    "for doc in tqdm(range(len(scores_en_fi))):\n",
    "    \n",
    "    # text from references_en_fi and translation_en_fi\n",
    "    text1 = references_en_fi_new[doc]\n",
    "    text2 = translation_en_fi_new[doc]\n",
    "    \n",
    "    encoded_input1 = tokenizer3(text1, return_tensors='tf')\n",
    "    output1 = model3(encoded_input1)\n",
    "    \n",
    "    encoded_input2 = tokenizer3(text2, return_tensors='tf')\n",
    "    output2 = model3(encoded_input2)\n",
    "    \n",
    "    last_hidden_states_1 = output1[0]\n",
    "    cls_embedding_1 = last_hidden_states_1[0][0]   \n",
    "    last_hidden_states_2 = output2[0]\n",
    "    cls_embedding_2 = last_hidden_states_2[0][0]\n",
    "    normalize_a = tf.nn.l2_normalize(cls_embedding_1,0)        \n",
    "    normalize_b = tf.nn.l2_normalize(cls_embedding_2,0)\n",
    "    cos_similarity=tf.reduce_sum(tf.multiply(normalize_a,normalize_b))\n",
    "    Cosine.append(float(cos_similarity))\n",
    "    \n",
    "scores_en_fi['Cosine_similarity_finBERT'] = pd.Series(Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4842557556811352"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print cosine similarity\n",
    "scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare cosine similarities for all models\n",
    "index = ['Multilingual BERT without pre-process', 'Multilingual BERT with pre-process', \n",
    "           'finBERT (TurkuNLP) without pre-process', 'finBERT (TurkuNLP) with pre-process']\n",
    "data = []\n",
    "columns = ['En-Fi']\n",
    "finish_corr = pd.DataFrame(data, columns=columns, index = index)\n",
    "finish_corr.iloc[0] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_base'])\n",
    "finish_corr.iloc[1] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity'])\n",
    "finish_corr.iloc[2] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT_base'])\n",
    "finish_corr.iloc[3] = scores_en_fi['z-score'].corr(scores_en_fi['Cosine_similarity_finBERT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>En-Fi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Multilingual BERT without pre-process</th>\n",
       "      <td>0.150627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multilingual BERT with pre-process</th>\n",
       "      <td>0.161529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finBERT (TurkuNLP) without pre-process</th>\n",
       "      <td>0.616468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finBERT (TurkuNLP) with pre-process</th>\n",
       "      <td>0.484256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           En-Fi\n",
       "Multilingual BERT without pre-process   0.150627\n",
       "Multilingual BERT with pre-process      0.161529\n",
       "finBERT (TurkuNLP) without pre-process  0.616468\n",
       "finBERT (TurkuNLP) with pre-process     0.484256"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
