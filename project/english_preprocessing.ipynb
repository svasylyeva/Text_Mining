{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cs = pd.read_csv(\"corpus/cs-en/scores.csv\")\n",
    "scores_de = pd.read_csv(\"corpus/de-en/scores.csv\")\n",
    "scores_en_fi = pd.read_csv(\"corpus/en-fi/scores.csv\")\n",
    "scores_en_zh = pd.read_csv(\"corpus/en-zh/scores.csv\")\n",
    "scores_ru = pd.read_csv(\"corpus/ru-en/scores.csv\")\n",
    "scores_zh = pd.read_csv(\"corpus/zh-en/scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED - HERE TO SHOW HOW CONTRACTIONS LOOK LIKE\n",
    "\n",
    "# contractions = { \n",
    "# \"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "# \"aren't\": \"are not / am not\",\n",
    "# \"can't\": \"cannot\",\n",
    "# \"can't've\": \"cannot have\",\n",
    "# \"'cause\": \"because\",\n",
    "# \"could've\": \"could have\",\n",
    "# \"couldn't\": \"could not\",\n",
    "# \"couldn't've\": \"could not have\",\n",
    "# \"didn't\": \"did not\",\n",
    "# \"doesn't\": \"does not\",\n",
    "# \"don't\": \"do not\",\n",
    "# \"hadn't\": \"had not\",\n",
    "# \"hadn't've\": \"had not have\",\n",
    "# \"hasn't\": \"has not\",\n",
    "# \"haven't\": \"have not\",\n",
    "# \"he'd\": \"he had / he would\",\n",
    "# \"he'd've\": \"he would have\",\n",
    "# \"he'll\": \"he shall / he will\",\n",
    "# \"he'll've\": \"he shall have / he will have\",\n",
    "# \"he's\": \"he has / he is\",\n",
    "# \"how'd\": \"how did\",\n",
    "# \"how'd'y\": \"how do you\",\n",
    "# \"how'll\": \"how will\",\n",
    "# \"how's\": \"how has / how is / how does\",\n",
    "# \"I'd\": \"I had / I would\",\n",
    "# \"I'd've\": \"I would have\",\n",
    "# \"I'll\": \"I shall / I will\",\n",
    "# \"I'll've\": \"I shall have / I will have\",\n",
    "# \"I'm\": \"I am\",\n",
    "# \"I've\": \"I have\",\n",
    "# \"isn't\": \"is not\",\n",
    "# \"it'd\": \"it had / it would\",\n",
    "# \"it'd've\": \"it would have\",\n",
    "# \"it'll\": \"it shall / it will\",\n",
    "# \"it'll've\": \"it shall have / it will have\",\n",
    "# \"it's\": \"it has / it is\",\n",
    "# \"let's\": \"let us\",\n",
    "# \"ma'am\": \"madam\",\n",
    "# \"mayn't\": \"may not\",\n",
    "# \"might've\": \"might have\",\n",
    "# \"mightn't\": \"might not\",\n",
    "# \"mightn't've\": \"might not have\",\n",
    "# \"must've\": \"must have\",\n",
    "# \"mustn't\": \"must not\",\n",
    "# \"mustn't've\": \"must not have\",\n",
    "# \"needn't\": \"need not\",\n",
    "# \"needn't've\": \"need not have\",\n",
    "# \"o'clock\": \"of the clock\",\n",
    "# \"oughtn't\": \"ought not\",\n",
    "# \"oughtn't've\": \"ought not have\",\n",
    "# \"shan't\": \"shall not\",\n",
    "# \"sha'n't\": \"shall not\",\n",
    "# \"shan't've\": \"shall not have\",\n",
    "# \"she'd\": \"she had / she would\",\n",
    "# \"she'd've\": \"she would have\",\n",
    "# \"she'll\": \"she shall / she will\",\n",
    "# \"she'll've\": \"she shall have / she will have\",\n",
    "# \"she's\": \"she has / she is\",\n",
    "# \"should've\": \"should have\",\n",
    "# \"shouldn't\": \"should not\",\n",
    "# \"shouldn't've\": \"should not have\",\n",
    "# \"so've\": \"so have\",\n",
    "# \"so's\": \"so as / so is\",\n",
    "# \"that'd\": \"that would / that had\",\n",
    "# \"that'd've\": \"that would have\",\n",
    "# \"that's\": \"that has / that is\",\n",
    "# \"there'd\": \"there had / there would\",\n",
    "# \"there'd've\": \"there would have\",\n",
    "# \"there's\": \"there has / there is\",\n",
    "# \"they'd\": \"they had / they would\",\n",
    "# \"they'd've\": \"they would have\",\n",
    "# \"they'll\": \"they shall / they will\",\n",
    "# \"they'll've\": \"they shall have / they will have\",\n",
    "# \"they're\": \"they are\",\n",
    "# \"they've\": \"they have\",\n",
    "# \"to've\": \"to have\",\n",
    "# \"wasn't\": \"was not\",\n",
    "# \"we'd\": \"we had / we would\",\n",
    "# \"we'd've\": \"we would have\",\n",
    "# \"we'll\": \"we will\",\n",
    "# \"we'll've\": \"we will have\",\n",
    "# \"we're\": \"we are\",\n",
    "# \"we've\": \"we have\",\n",
    "# \"weren't\": \"were not\",\n",
    "# \"what'll\": \"what shall / what will\",\n",
    "# \"what'll've\": \"what shall have / what will have\",\n",
    "# \"what're\": \"what are\",\n",
    "# \"what's\": \"what has / what is\",\n",
    "# \"what've\": \"what have\",\n",
    "# \"when's\": \"when has / when is\",\n",
    "# \"when've\": \"when have\",\n",
    "# \"where'd\": \"where did\",\n",
    "# \"where's\": \"where has / where is\",\n",
    "# \"where've\": \"where have\",\n",
    "# \"who'll\": \"who shall / who will\",\n",
    "# \"who'll've\": \"who shall have / who will have\",\n",
    "# \"who's\": \"who has / who is\",\n",
    "# \"who've\": \"who have\",\n",
    "# \"why's\": \"why has / why is\",\n",
    "# \"why've\": \"why have\",\n",
    "# \"will've\": \"will have\",\n",
    "# \"won't\": \"will not\",\n",
    "# \"won't've\": \"will not have\",\n",
    "# \"would've\": \"would have\",\n",
    "# \"wouldn't\": \"would not\",\n",
    "# \"wouldn't've\": \"would not have\",\n",
    "# \"y'all\": \"you all\",\n",
    "# \"y'all'd\": \"you all would\",\n",
    "# \"y'all'd've\": \"you all would have\",\n",
    "# \"y'all're\": \"you all are\",\n",
    "# \"y'all've\": \"you all have\",\n",
    "# \"you'd\": \"you had / you would\",\n",
    "# \"you'd've\": \"you would have\",\n",
    "# \"you'll\": \"you shall / you will\",\n",
    "# \"you'll've\": \"you shall have / you will have\",\n",
    "# \"you're\": \"you are\",\n",
    "# \"you've\": \"you have\"\n",
    "# }\n",
    "\n",
    "# contractions_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
    "# def expand_contractions(s, contractions = contractions):\n",
    "#     def replace(match):\n",
    "#         return contractions[match.group(0)]\n",
    "#     return contractions_re.sub(replace, s)\n",
    "\n",
    "# expand_contractions(\"ain't stop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as previous cell but pycontractes choose a proper form\n",
    "# instead ambiguous \"you'd\" -> \"you had / you would\"\n",
    "# using contractions lib pycontractions\n",
    "from pycontractions import Contractions\n",
    "\n",
    "cont = Contractions('GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "# optional, prevents loading on first expand_texts call\n",
    "cont.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = scores_de.translation\n",
    "a[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.Series(list(cont.expand_texts(a, precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it is now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As contraction extractions works really slow\n",
    "# it was done outside preprocessing function\n",
    "references_cs = pd.Series(list(cont.expand_texts(scores_cs['reference'], precise=True)))\n",
    "references_de = pd.Series(list(cont.expand_texts(scores_de['reference'], precise=True)))\n",
    "references_ru = pd.Series(list(cont.expand_texts(scores_ru['reference'], precise=True)))\n",
    "references_zh = pd.Series(list(cont.expand_texts(scores_zh['reference'], precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for transaltions\n",
    "translation_cs = pd.Series(list(cont.expand_texts(scores_cs['translation'], precise=True)))\n",
    "translation_de = pd.Series(list(cont.expand_texts(scores_de['translation'], precise=True)))\n",
    "translation_ru = pd.Series(list(cont.expand_texts(scores_ru['translation'], precise=True)))\n",
    "translation_zh = pd.Series(list(cont.expand_texts(scores_zh['translation'], precise=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.    ---->  \n",
      " it is now time to look at the needs of community legal centres and their client communities, and for the Palaszczuk government to invest in this important work.\n"
     ]
    }
   ],
   "source": [
    "# Check how expanding contractions worked\n",
    "print(scores_de['translation'][6], '   ---->  \\n',translation_de[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release references and 'garbage collect' to free memory\n",
    "import gc\n",
    "del cont\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(series, pontuation = False):\n",
    "    processed_corpus = []\n",
    "    #stop_words = set(stopwords.words())\n",
    "    for i in tqdm(range(len(series))):\n",
    "        text = series[i]\n",
    "        \n",
    "        #remove tags\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        #Remove punctuations\n",
    "        if pontuation==True:\n",
    "            text = re.sub(r'[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，？、~@#￥%……&*（）:：；《）《》“”()»〔〕-]+', ' ', text)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Convert to list from string\n",
    "        text = text.split()\n",
    "\n",
    "        #Lemmatisation\n",
    "        lem = WordNetLemmatizer()\n",
    "        #text = [lem.lemmatize(word) for word in text if not word in stop_words] \n",
    "        text = \" \".join(text)\n",
    "        processed_corpus.append(text)\n",
    "    return processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-c106e6b4224f>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(series))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a338339dbd1496ca780e4a6cb403792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa323b369bb94664ad458cd1468e0e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f02eaf0cd034273b17f5d8e8ed9e728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e67a545d4d49f899c250833cf734e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870b4dc140924b669add34ecaeb3c49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murmu\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4d62376dd5495c9666880c20a622d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "references_cs = preprocessing(references_cs)\n",
    "references_de = preprocessing(references_de)\n",
    "references_en_fi = preprocessing(scores_en_fi['reference'])\n",
    "references_en_zh = preprocessing(scores_en_zh['reference'])\n",
    "references_ru = preprocessing(references_ru)\n",
    "references_zh = preprocessing(references_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-c106e6b4224f>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm(range(len(series))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad41ff4c9a740049128138342bb9fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11585.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9da3440cd034cc48e8e68b958bc7d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=21704.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0282644b5516458492d56a0eedb36ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6748.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4828834f3a804602b5155c94795f3d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84714f6d09b54a6c91a1e91b5ddd05f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17980.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c418abeac805441382756dc9eac98871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "translation_cs = preprocessing(translation_cs)\n",
    "translation_de = preprocessing(translation_de)\n",
    "translation_en_fi = preprocessing(scores_en_fi['translation'])\n",
    "translation_en_zh = preprocessing(scores_en_zh['translation'])\n",
    "translation_ru = preprocessing(translation_ru)\n",
    "translation_zh = preprocessing(translation_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nltk.translate.chrf_score as chrf\n",
    "from rouge import Rouge\n",
    "import nltk\n",
    "import nltk.translate.gleu_score as gleu\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "try:\n",
    "  nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "  nltk.download('punkt')\n",
    "import nltk.translate.meteor_score as meteor\n",
    "import nltk.translate.nist_score as nist\n",
    "import nltk.translate.bleu_score as bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS from text_mining1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chrf_metric(translation, references):\n",
    "    chrf_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = chrf.sentence_chrf([translation[i]], references[i])\n",
    "        chrf_metric.append(row)\n",
    "    return chrf_metric\n",
    "\n",
    "chf_cs = chrf_metric(translation_cs, references_cs)\n",
    "scores_cs['chf'] = chf_cs\n",
    "chf_de = chrf_metric(translation_de, references_de)\n",
    "scores_de['chf'] = chf_de\n",
    "chf_en_fi = chrf_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['chf'] = chf_en_fi\n",
    "chf_en_zh = chrf_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['chf'] = chf_en_zh\n",
    "chf_ru = chrf_metric(translation_ru, references_ru)\n",
    "scores_ru['chf'] = chf_ru\n",
    "chf_zh = chrf_metric(translation_zh, references_zh)\n",
    "scores_zh['chf'] = chf_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gleu_metric(translation, references):\n",
    "    gleu_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = gleu.sentence_gleu([str(references[i]).split()], str(translation[i]).split(), min_len=1, max_len=2)\n",
    "        gleu_metric.append(row)\n",
    "    return gleu_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "gleu_cs = gleu_metric(translation_cs, references_cs)\n",
    "scores_cs['gleu'] = gleu_cs\n",
    "\n",
    "gleu_de = gleu_metric(translation_de, references_de)\n",
    "scores_de['gleu'] = gleu_de\n",
    "\n",
    "gleu_en_fi = gleu_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['gleu'] = gleu_en_fi\n",
    "\n",
    "gleu_en_zh = gleu_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['gleu'] = gleu_en_zh\n",
    "\n",
    "gleu_ru = gleu_metric(translation_ru, references_ru)\n",
    "scores_ru['gleu'] = gleu_ru\n",
    "\n",
    "gleu_zh = gleu_metric(translation_zh, references_zh)\n",
    "scores_zh['gleu'] = gleu_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meteor_metric(translation, references):\n",
    "    meteor_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (meteor.meteor_score([translation[i]], references[i]))\n",
    "        meteor_metric.append(row)\n",
    "    return meteor_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteor_cs = meteor_metric(translation_cs, references_cs)\n",
    "scores_cs['meteor'] = meteor_cs\n",
    "\n",
    "meteor_de = meteor_metric(translation_de, references_de)\n",
    "scores_de['meteor'] = meteor_de\n",
    "\n",
    "meteor_en_fi = meteor_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['meteor'] = meteor_en_fi\n",
    "\n",
    "meteor_en_zh = meteor_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['meteor'] = meteor_en_zh\n",
    "\n",
    "meteor_ru = meteor_metric(translation_ru, references_ru)\n",
    "scores_ru['meteor'] = meteor_ru\n",
    "\n",
    "meteor_zh = meteor_metric(translation_zh, references_zh)\n",
    "scores_zh['meteor'] = meteor_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murmu\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\murmu\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\murmu\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "def bleu_metric(translation, references):\n",
    "    bleu_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (bleu.sentence_bleu([translation[i]], references[i]))\n",
    "        bleu_metric.append(row)\n",
    "    return bleu_metric\n",
    "\n",
    "bleu_cs = bleu_metric(translation_cs, references_cs)\n",
    "scores_cs['bleu'] = bleu_cs\n",
    "\n",
    "bleu_de = bleu_metric(translation_de, references_de)\n",
    "scores_de['bleu'] = bleu_de\n",
    "\n",
    "bleu_en_fi = bleu_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['bleu'] = bleu_en_fi\n",
    "\n",
    "bleu_en_zh = bleu_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['bleu'] = bleu_en_zh\n",
    "\n",
    "bleu_ru = bleu_metric(translation_ru, references_ru)\n",
    "scores_ru['bleu'] = bleu_ru\n",
    "\n",
    "bleu_zh = bleu_metric(translation_zh, references_zh)\n",
    "scores_zh['bleu'] = bleu_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nist_metric(translation, references):\n",
    "    nist_metric = []\n",
    "    for i in range(len(translation)):\n",
    "        row = (nist.sentence_nist([translation[i]], references[i],n=1))\n",
    "        nist_metric.append(row)\n",
    "    return nist_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nist_cs = nist_metric(translation_cs, references_cs)\n",
    "scores_cs['nist'] = nist_cs\n",
    "\n",
    "nist_de = nist_metric(translation_de, references_de)\n",
    "scores_de['nist'] = nist_de\n",
    "\n",
    "nist_en_fi = nist_metric(translation_en_fi, references_en_fi)\n",
    "scores_en_fi['nist'] = nist_en_fi\n",
    "\n",
    "nist_en_zh = nist_metric(translation_en_zh, references_en_zh)\n",
    "scores_en_zh['nist'] = nist_en_zh\n",
    "\n",
    "nist_ru = nist_metric(translation_ru, references_ru)\n",
    "scores_ru['nist'] = nist_ru\n",
    "\n",
    "nist_zh = nist_metric(translation_zh, references_zh)\n",
    "scores_zh['nist'] = nist_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(scores):\n",
    "    chf = scores['z-score'].corr(scores['chf'])\n",
    "    gleu = scores['z-score'].corr(scores['gleu'])\n",
    "    meteor = scores['z-score'].corr(scores['meteor'])\n",
    "    bleu = scores['z-score'].corr(scores['bleu'])\n",
    "    nist = scores['z-score'].corr(scores['nist'])\n",
    "    #ribes = scores['z-score'].corr(scores['ribes'])\n",
    "    corr = [chf, gleu, meteor, bleu, nist]\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_cs = corr(scores_cs)\n",
    "corr_de = corr(scores_de)\n",
    "corr_en_fi = corr(scores_en_fi)\n",
    "corr_en_zh = corr(scores_en_zh)\n",
    "corr_ru = corr(scores_ru)\n",
    "corr_zh = corr(scores_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['chf', 'gleu', 'meteor', 'bleu', 'nist']\n",
    "data = []\n",
    "index = ['scores_cs', 'scores_de', 'scores_en_fi', 'scores_en_zh', 'scores_ru', 'scores_zh']\n",
    "correlation = pd.DataFrame(data, columns=columns, index = index)\n",
    "correlation.iloc[0] = corr_cs\n",
    "correlation.iloc[1] = corr_de\n",
    "correlation.iloc[2] = corr_en_fi\n",
    "correlation.iloc[3] = corr_en_zh\n",
    "correlation.iloc[4] = corr_ru\n",
    "correlation.iloc[5] = corr_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chf</th>\n",
       "      <th>gleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>bleu</th>\n",
       "      <th>nist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scores_cs</th>\n",
       "      <td>0.462233</td>\n",
       "      <td>0.427893</td>\n",
       "      <td>0.440004</td>\n",
       "      <td>0.468779</td>\n",
       "      <td>0.334652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_de</th>\n",
       "      <td>0.341149</td>\n",
       "      <td>0.310098</td>\n",
       "      <td>0.30805</td>\n",
       "      <td>0.346757</td>\n",
       "      <td>0.227363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_fi</th>\n",
       "      <td>0.611567</td>\n",
       "      <td>0.494636</td>\n",
       "      <td>0.491475</td>\n",
       "      <td>0.619928</td>\n",
       "      <td>0.423513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_en_zh</th>\n",
       "      <td>0.435736</td>\n",
       "      <td>0.0296857</td>\n",
       "      <td>0.0231177</td>\n",
       "      <td>0.433811</td>\n",
       "      <td>0.444757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_ru</th>\n",
       "      <td>0.361417</td>\n",
       "      <td>0.333536</td>\n",
       "      <td>0.336745</td>\n",
       "      <td>0.367581</td>\n",
       "      <td>0.26207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scores_zh</th>\n",
       "      <td>0.341204</td>\n",
       "      <td>0.317924</td>\n",
       "      <td>0.326358</td>\n",
       "      <td>0.351904</td>\n",
       "      <td>0.244659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   chf       gleu     meteor      bleu      nist\n",
       "scores_cs     0.462233   0.427893   0.440004  0.468779  0.334652\n",
       "scores_de     0.341149   0.310098    0.30805  0.346757  0.227363\n",
       "scores_en_fi  0.611567   0.494636   0.491475  0.619928  0.423513\n",
       "scores_en_zh  0.435736  0.0296857  0.0231177  0.433811  0.444757\n",
       "scores_ru     0.361417   0.333536   0.336745  0.367581   0.26207\n",
       "scores_zh     0.341204   0.317924   0.326358  0.351904  0.244659"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
